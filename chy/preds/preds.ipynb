{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "9a365691-09d1-4778-ac74-81601c98af38",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import labs\n",
    "import preds\n",
    "import cnnm\n",
    "import inv \n",
    "\n",
    "importlib.reload(labs)\n",
    "importlib.reload(preds)\n",
    "importlib.reload(cnnm)\n",
    "importlib.reload(inv)\n",
    "\n",
    "from labs import *\n",
    "from inv import *\n",
    "from preds import *\n",
    "from cnnm import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d0eb6e8-65ca-4dfc-9bd6-a7cdc8e0a436",
   "metadata": {},
   "source": [
    "# Predictor\n",
    "- 훈련 데이터에 오라벨된 것이 있는지"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e3128bfe-8afc-46d5-9a58-0197220d23f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "255861df70e44ddfa864d1077a3733da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "3140"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "image_paths = grep_files('/data/ephemeral/home/dataset/docsy-deskew/', exts=['jpg'])\n",
    "len(image_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "80121b6e-81d1-4733-bfa2-6ca2969de348",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.52, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    }
   ],
   "source": [
    "processor = AutoImageProcessor.from_pretrained('facebook/convnextv2-large-22k-384')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "b0285ea5-0c68-4cca-a9dc-10b9c7518650",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of ConvNextV2ForImageClassification were not initialized from the model checkpoint at facebook/convnextv2-large-22k-384 and are newly initialized because the shapes did not match:\n",
      "- classifier.bias: found shape torch.Size([1000]) in the checkpoint and torch.Size([17]) in the model instantiated\n",
      "- classifier.weight: found shape torch.Size([1000, 1536]) in the checkpoint and torch.Size([17, 1536]) in the model instantiated\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "ckpt_path = './ckpt/exp-convnext-large-384-easy-rotator-dice-loss-add-last_epoch.ckpt'\n",
    "classes_path = '/data/ephemeral/home/dataset/dtc/doc_classes.json'\n",
    "predictor = Predictor(CNN, processor, ckpt_path, classes_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd12b97f-c9b4-4636-b149-2b849ac7e852",
   "metadata": {},
   "source": [
    "# TEST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "b1555bf4-e26a-4ff4-9f1e-a6f80b02f1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run(idx):\n",
    "    p = image_paths[idx]\n",
    "    df = predictor.feed_bty(p)\n",
    "\n",
    "    cols_to_drop = df.columns[(df < 0.01).all(axis=0)]\n",
    "    filtered_df = df.drop(columns=cols_to_drop)\n",
    "    \n",
    "    display(filtered_df)\n",
    "    show_img(path=p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "30ce2cdc-7ca2-4b01-9e51-0d48240a0af8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = run(64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc9f7ff-ac84-4700-a2b0-552bd0f7b2b8",
   "metadata": {},
   "source": [
    "# TEST ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "9964f747-fa04-41ba-b384-bf61cf7a371f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d92ec7a5206941bdadd31f551d582ef5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "items = predictor.test(image_paths[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "7fc83c25-6eb3-4323-a247-e2cf6e19b6da",
   "metadata": {},
   "outputs": [],
   "source": [
    "write_list('./cnv2-easy-rot-dice-loss.txt', items)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a75274a9-8287-41dd-ac49-7770d95b6ed8",
   "metadata": {},
   "source": [
    "# Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "6a74d7e9-8206-464d-97d3-f15fab6c0407",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrongs = read_list_from_txt('inconsist_list.txt')\n",
    "base_dir = '/data/ephemeral/home/dataset/docsy-deskew/'\n",
    "paths = [os.path.join(base_dir, i) for i in wrongs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "39919a26-0821-4148-a8fe-4b7aa03841db",
   "metadata": {},
   "outputs": [],
   "source": [
    "answers = [(item[0][:-6] + '.jpg', np.argmax(np.array(item[1])), np.array(item[1]).max()) for item in items]\n",
    "df = pd.DataFrame(answers, columns=['ID', 'target', 'prob'])\n",
    "hists = [ df ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "fb19e4d5-f5a9-4a2f-b886-1027b982b54a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8ee3dcec7354726a40b4beda93bae6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(Button(description='PREV', style=ButtonStyle()), Button(description='NEXT', styl…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "inv = ImageNavigator(paths, hists, id2kor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "py12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
