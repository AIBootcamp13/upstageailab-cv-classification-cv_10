{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abff719-4661-45ce-8313-144423701d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import labs\n",
    "\n",
    "importlib.reload(labs)\n",
    "from labs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbb40d-3091-4032-bdb4-0b9e2e4a16e1",
   "metadata": {},
   "source": [
    "# INIT. Processor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab262aa5-4743-4ac4-bcf8-8f3021fb1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fd9eb7-9002-48a8-8930-b7d335a8dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae305cca-c5b4-4ddd-8229-44776efef5aa",
   "metadata": {},
   "source": [
    "# DEF. Dataset and DataModule \n",
    "- TODO) D1~3 동일 구조로 변환한 json만들고 이를 사용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bca021a8-d798-4263-b819-d16446630e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D4Dataset(Dataset):\n",
    "    def __init__(self, image_paths, label_map, processor):\n",
    "        self.label2id = label_map\n",
    "        self.processor = processor\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        encoding = prepare_example(image_path, self.processor)\n",
    "        label = self.label2id[encoding['doc_class_str']]\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"bbox\": encoding[\"bbox\"].squeeze(0),\n",
    "            \"pixel_values\": encoding[\"pixel_values\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "44e83f36-eae8-4744-b69a-1b8e35542933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D4DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_paths,\n",
    "        valid_paths,\n",
    "        trial_paths,\n",
    "        label_map,\n",
    "        processor,\n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_paths = train_paths\n",
    "        self.valid_paths = valid_paths\n",
    "        self.trial_paths = trial_paths\n",
    "        self.label_map = label_map\n",
    "        self.processor = processor\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\":\n",
    "            self.train_ds = D4Dataset(self.train_paths, self.label_map, self.processor)\n",
    "            self.valid_ds = D4Dataset(self.valid_paths, self.label_map, self.processor)\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.trial_ds = D4Dataset(self.trial_paths, self.label_map, self.processor)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator \n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trial_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd45ba1-cf97-4b28-af13-5d6d51bf5935",
   "metadata": {},
   "source": [
    "# INIT. DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "244706ef-68df-49c4-8a03-5ce376dbce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "290a225fcd2d4d93b69d95d1fc043188",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_paths = grep_files(\"/data/ephemeral/home/dataset/dataset-d3p/\", exts=['jpg'])\n",
    "label_path = \"/data/ephemeral/home/dataset/dataset-d3p/doc_classes.json\"\n",
    "label2id, id2label = make_doc_class_mapper(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5833dd72-ceb6-469f-922b-cc670e47bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, valid_images, trial_images = split_ds(image_paths)\n",
    "\n",
    "data_module = D4DataModule(\n",
    "    train_paths=train_images,\n",
    "    valid_paths=valid_images,\n",
    "    trial_paths=trial_images,\n",
    "    label_map=label2id,\n",
    "    processor=processor,\n",
    "    batch_size=16,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b638a78d-411d-4fa0-8e40-cc7b65a49660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# s0 = data_module.train_ds[0]\n",
    "# print(s0.keys())\n",
    "# print(s0['input_ids'].shape, s0['attention_mask'].shape, s0['bbox'].shape, s0['pixel_values'].shape, s0['labels'].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae712d2-7102-4593-99a7-42e9fbe8ce8e",
   "metadata": {},
   "source": [
    "# DEF) Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20dd9da8-13ec-43c3-9d91-2723454bcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3ForSequenceClassification as LyLmv3, LayoutLMv3Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cf9574-b7cc-4ba7-85f3-beac25fae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lym(pl.LightningModule):\n",
    "    def __init__(self, label2id, id2label):\n",
    "        super().__init__()\n",
    "        num_classes = len(label2id)\n",
    "        self.model = LyLmv3.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=num_classes)\n",
    "        self.model.config.label2id = label2id\n",
    "        self.model.config.id2label = id2label\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
    "            # \"top-3 accuracy\" : MulticlassAccuracy(num_classes=10, top_k=3),\n",
    "            \"roc_auc\": AUROC(task=\"multiclass\", num_classes=num_classes),\n",
    "            \"precision\": Precision(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "            \"recall\": Recall(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "            \"F1\": F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "        }\n",
    "\n",
    "        self.train_metrics = MetricCollection(metrics, prefix=\"train_\")\n",
    "        self.valid_metrics = MetricCollection(metrics, prefix=\"valid_\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, bbox, pixel_values, labels=None):\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            bbox=bbox,\n",
    "            pixel_values=pixel_values,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "    def feed(self, batch):\n",
    "        return self(\n",
    "            batch[\"input_ids\"],\n",
    "            batch[\"attention_mask\"],\n",
    "            batch[\"bbox\"],\n",
    "            batch[\"pixel_values\"],\n",
    "            batch[\"labels\"]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self.feed(batch)\n",
    "    \n",
    "        self.train_metrics.update(outputs.logits, labels)\n",
    "        \n",
    "        self.log(\"train_loss\", outputs.loss)\n",
    "        for name, metric in self.train_metrics.items():\n",
    "            self.log(name, metric.compute(), prog_bar=True)\n",
    "        \n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self.feed(batch)\n",
    "\n",
    "        self.valid_metrics.update(outputs.logits, labels)\n",
    "        \n",
    "        self.log(\"valid_loss\", outputs.loss)\n",
    "        for name, metric in self.valid_metrics.items():\n",
    "            self.log(name, metric.compute(), prog_bar=True)\n",
    "        return outputs.loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=1e-5)\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.train_metrics.compute()\n",
    "        for name, value in metrics.items():\n",
    "            self.log(name, value)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.valid_metrics.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        try:\n",
    "            metrics = self.valid_metrics.compute()\n",
    "            for k, v in metrics.items():\n",
    "                self.log(k, v)\n",
    "        except Exception as e:\n",
    "            print(f\"Metric compute error: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd8e2e-e0c4-467a-aeaf-d4421531f665",
   "metadata": {},
   "source": [
    "# RUN. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b92995c1-7962-4108-b6e8-1b44b6cacf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/.pyenv/versions/catch/lib/python3.12/site-packages/lightning_fabric/connector.py:571: `precision=16` is supported for historical reasons but its usage is discouraged. Please set your precision to 16-mixed instead!\n",
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                                | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model         | LayoutLMv3ForSequenceClassification | 125 M  | eval \n",
      "1 | train_metrics | MetricCollection                    | 0      | train\n",
      "2 | valid_metrics | MetricCollection                    | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "503.806   Total estimated model params size (MB)\n",
      "7         Modules in train mode\n",
      "243       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55542e4f7d814c7ba8f23ef347d157b8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/.pyenv/versions/catch/lib/python3.12/site-packages/transformers/modeling_utils.py:1072: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/.pyenv/versions/catch/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20ddc84a2fb746c7a7b3915de7042a76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2456b988f98c4bae9e3decc7e0be36c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "25969ba8c049422d95ca909e90cfc00a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b60781ef65cf4d1d86892def7264815c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0a4960fda9254860b00285eb3c116a62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b81695fd252475b96b05a5a5a0e7963",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5366f782da014ad693372456fea96b26",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aba3e5d271cb4ca1877e2f591c6a46d1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "16bb4f6c094c437aaef1f4b052b08c1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14fc267e85bf4eecbfd216f756b8ffe7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "765fe82f886742ab87c72551a5cba430",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "480956dfa5024acfbad4907750f27c23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d285beaf01ee453f8a617024d1b494b4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75b911be2295484a9275b9c31f85b63d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "660f705ca1dc445fb92f20a391d636e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a367ae312f814e1b9e69a6b9974ee981",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3bf948b7cb6e4b8a9eae3cde49b1f697",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='valid_loss', patience=5, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\", save_top_k=3)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=16,\n",
    "    max_epochs=20,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model = Lym(label2id, id2label)\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a406e330-d902-4568-bebb-e7e4479f5a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 13'15 ~ 14:00 15epoch"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catch12",
   "language": "python",
   "name": "catch12"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
