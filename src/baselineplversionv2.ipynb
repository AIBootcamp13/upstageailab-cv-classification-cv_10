{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb390275",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535a302",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e02795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import wandb\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from augraphy import *\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d62d501",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "403efce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convnext_base.fb_in22k_ft_in1k,32,80,0.0001</strong> at: <a href='https://wandb.ai/hoppure-/pl-migration/runs/9y0ii0hk' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration/runs/9y0ii0hk</a><br> View project at: <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250703_163151-9y0ii0hk/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "11f1e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_list = {\n",
    "    1 : 'resnet34',\n",
    "    2 : 'resnet50',\n",
    "    3 : 'resnet101',\n",
    "    4 : 'resnet152',\n",
    "    6 : 'vit_small_patch16_224',\n",
    "    5 : 'vit_base_patch16_224',\n",
    "    7 : 'convnext_base.fb_in22k_ft_in1k',\n",
    "    8 : 'vit_large_patch16_224',\n",
    "    9 : 'convnextv2_huge.fcmae_ft_in1k'\t, # Out of Memory\n",
    "    10 : 'convnext_large.fb_in22k_ft_in1k', # Out of Memory\n",
    "    11 : \"convnextv2_base.fcmae_ft_in1k\",\n",
    "    12 : 'convnext_base.fb_in22k_ft_in1k_384'\t\n",
    "\n",
    "}\n",
    "\n",
    "model_family = {\"resnet\" : [model_list[1],\n",
    "                            model_list[2],\n",
    "                            model_list[3],\n",
    "                            model_list[4],\n",
    "                            model_list[7],\n",
    "                            model_list[9],\n",
    "                            model_list[10],\n",
    "                            model_list[11],\n",
    "                            model_list[12],],\n",
    "                \"vit\" : [model_list[6],\n",
    "                         model_list[5],\n",
    "                         model_list[8]]\n",
    "                            }\n",
    "\n",
    "num_classes=17\n",
    "\n",
    "# training config\n",
    "\n",
    "CFS={\"MODEL\" : model_list[7],\n",
    "    \"IMG_SIZE\" : 224,\n",
    "     \"LR\" : 1e-4,\n",
    "    'EPOCHS' : 80,\n",
    "    'BATCH_SIZE' : 32,\n",
    "    \"NUM_WORKERS\" : 16,}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"pl-migration\",\n",
    "    name=f\"{CFS['MODEL']},{CFS['BATCH_SIZE']},{CFS['EPOCHS']},{CFS['LR']}\",\n",
    "    config=CFS,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8725f",
   "metadata": {},
   "source": [
    "# Augraphy  작업중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51377b60",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ink_phase = [\n",
    "    InkBleed(\n",
    "        intensity_range=(0.5, 0.6),\n",
    "        kernel_size=random.choice([(5, 5), (3, 3)]),\n",
    "        severity=(0.2, 0.4),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    OneOf(\n",
    "        [\n",
    "            InkShifter(\n",
    "                text_shift_scale_range=(18, 27),\n",
    "                text_shift_factor_range=(1, 4),\n",
    "                text_fade_range=(0, 2),\n",
    "                blur_kernel_size=(5, 5),\n",
    "                blur_sigma=0,\n",
    "                noise_type=\"random\",\n",
    "            ),\n",
    "            BleedThrough(\n",
    "                intensity_range=(0.1, 0.3),\n",
    "                color_range=(32, 224),\n",
    "                ksize=(17, 17),\n",
    "                sigmaX=1,\n",
    "                alpha=random.uniform(0.1, 0.2),\n",
    "                offsets=(10, 20),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "]\n",
    "\n",
    "paper_phase = [\n",
    "\n",
    "    ColorPaper(\n",
    "        hue_range=(0, 255),\n",
    "        saturation_range=(10, 40),\n",
    "        p=0.33,\n",
    "    ),\n",
    "            OneOf(\n",
    "        [\n",
    "            DelaunayTessellation(\n",
    "                n_points_range=(500, 800),\n",
    "                n_horizontal_points_range=(500, 800),\n",
    "                n_vertical_points_range=(500, 800),\n",
    "                noise_type=\"random\",\n",
    "                color_list=\"default\",\n",
    "                color_list_alternate=\"default\",\n",
    "            ),\n",
    "            PatternGenerator(\n",
    "                imgx=random.randint(256, 512),\n",
    "                imgy=random.randint(256, 512),\n",
    "                n_rotation_range=(10, 15),\n",
    "                color=\"random\",\n",
    "                alpha_range=(0.25, 0.5),\n",
    "            ),\n",
    "            VoronoiTessellation(\n",
    "                mult_range=(50, 80),\n",
    "                seed=19829813472,\n",
    "                num_cells_range=(500, 1000),\n",
    "                noise_type=\"random\",\n",
    "                background_value=(200, 255),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "    AugmentationSequence(\n",
    "        [\n",
    "            NoiseTexturize(\n",
    "                sigma_range=(3, 10),\n",
    "                turbulence_range=(2, 5),\n",
    "            ),\n",
    "            BrightnessTexturize(\n",
    "                texturize_range=(0.9, 0.99),\n",
    "                deviation=0.03,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "post_phase = [\n",
    "    OneOf(\n",
    "        [\n",
    "            DirtyDrum(\n",
    "                line_width_range=(1, 6),\n",
    "                line_concentration=random.uniform(0.05, 0.15),\n",
    "                direction=random.randint(0, 2),\n",
    "                noise_intensity=random.uniform(0.6, 0.95),\n",
    "                noise_value=(64, 224),\n",
    "                ksize=random.choice([(3, 3), (5, 5), (7, 7)]),\n",
    "                sigmaX=0,\n",
    "                p=0.2,\n",
    "            ),\n",
    "            DirtyRollers(\n",
    "                line_width_range=(2, 32),\n",
    "                scanline_type=0,\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "    SubtleNoise(\n",
    "        subtle_range=random.randint(5, 10),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    Jpeg(\n",
    "        quality_range=(25, 95),\n",
    "        p=0.33,\n",
    "    ),\n",
    "\n",
    "    OneOf(\n",
    "        [\n",
    "            Markup(\n",
    "                num_lines_range=(2, 7),\n",
    "                markup_length_range=(0.5, 1),\n",
    "                markup_thickness_range=(1, 2),\n",
    "                markup_type=random.choice([\"strikethrough\", \"crossed\", \"highlight\", \"underline\"]),\n",
    "                markup_color=\"random\",\n",
    "                single_word_mode=False,\n",
    "                repetitions=1,\n",
    "            ),\n",
    "            Scribbles(\n",
    "                scribbles_type=\"random\",\n",
    "                scribbles_location=\"random\",\n",
    "                scribbles_size_range=(250, 600),\n",
    "                scribbles_count_range=(1, 6),\n",
    "                scribbles_thickness_range=(1, 3),\n",
    "                scribbles_brightness_change=[32, 64, 128],\n",
    "                scribbles_text=\"random\",\n",
    "                scribbles_text_font=\"random\",\n",
    "                scribbles_text_rotate_range=(0, 360),\n",
    "                scribbles_lines_stroke_count_range=(1, 6),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "            OneOf(\n",
    "        [\n",
    "            GlitchEffect(\n",
    "                glitch_direction=\"random\",\n",
    "                glitch_number_range=(8, 16),\n",
    "                glitch_size_range=(5, 50),\n",
    "                glitch_offset_range=(10, 50),\n",
    "            ),\n",
    "            ColorShift(\n",
    "                color_shift_offset_x_range=(3, 5),\n",
    "                color_shift_offset_y_range=(3, 5),\n",
    "                color_shift_iterations=(2, 3),\n",
    "                color_shift_brightness_range=(0.9, 1.1),\n",
    "                color_shift_gaussian_kernel_range=(3, 3),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "    BadPhotoCopy(\n",
    "        mask=None,\n",
    "        noise_type=-1,\n",
    "        noise_side=\"random\",\n",
    "        noise_iteration=(1, 2),\n",
    "        noise_size=(1, 3),\n",
    "        noise_value=(128, 196),\n",
    "        noise_sparsity=(0.3, 0.6),\n",
    "        noise_concentration=(0.1, 0.6),\n",
    "        blur_noise=random.choice([True, False]),\n",
    "        blur_noise_kernel=random.choice([(3, 3), (5, 5), (7, 7)]),\n",
    "        wave_pattern=random.choice([True, False]),\n",
    "        edge_effect=random.choice([True, False]),\n",
    "        p=0.33,\n",
    "    ),\n",
    "\n",
    "            Faxify(\n",
    "        scale_range=(0.3, 0.6),\n",
    "        monochrome=random.choice([0, 1]),\n",
    "        monochrome_method=\"random\",\n",
    "        monochrome_arguments={},\n",
    "        halftone=random.choice([0, 1]),\n",
    "        invert=1,\n",
    "        half_kernel_size=random.choice([(1, 1), (2, 2)]),\n",
    "        angle=(0, 360),\n",
    "        sigma=(1, 3),\n",
    "        p=0.33,\n",
    "    ),\n",
    "]\n",
    "\n",
    "pipeline = AugraphyPipeline(ink_phase=ink_phase, paper_phase=paper_phase, post_phase=post_phase)\n",
    "\n",
    "\n",
    "image = cv2.imread(\"image.png\")\n",
    "\n",
    "image_augmented = pipeline(image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dc071",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e06151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스코어가 하락한 augementation 모음\n",
    "\n",
    "# A.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, rotate=(-15, 15), scale=(0.9, 1.1), shear=(-10, 10), p=0.5),\n",
    "# A.Perspective(scale=(0.05, 0.1), p=0.5),\n",
    "# A.SquareSymmetry(p=0.2),\n",
    "# A.Transpose(p=0.5), \n",
    "# A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.3),\n",
    "# A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.2)\n",
    "# A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.2)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b74e90a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/.pyenv/versions/3.12.10/envs/py12/lib/python3.12/site-packages/albumentations/core/validation.py:114: UserWarning: ShiftScaleRotate is a special case of Affine transform. Please use Affine transform instead.\n",
      "  original_init(self, **validated_kwargs)\n",
      "/tmp/ipykernel_553175/2580719664.py:24: UserWarning: Argument(s) 'alpha_affine' are not valid for transform ElasticTransform\n",
      "  A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
      "/tmp/ipykernel_553175/2580719664.py:36: UserWarning: Argument(s) 'var_limit, mean' are not valid for transform GaussNoise\n",
      "  A.GaussNoise(var_limit=(10.0, 50.0), mean=0.0, per_channel=True, p=0.4),\n",
      "/tmp/ipykernel_553175/2580719664.py:43: UserWarning: Argument(s) 'max_holes, max_height, max_width, fill_value' are not valid for transform CoarseDropout\n",
      "  A.CoarseDropout(max_holes=8, max_height=16, max_width=16, fill_value=0, p=0.5), # cutout\n",
      "/tmp/ipykernel_553175/2580719664.py:45: UserWarning: Argument(s) 'num_shadows_lower, num_shadows_upper' are not valid for transform RandomShadow\n",
      "  A.RandomShadow(num_shadows_lower=1, num_shadows_upper=3, p=0.2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250703_163246-qv19z0sy</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hoppure-/pl-migration/runs/qv19z0sy' target=\"_blank\">convnext_base.fb_in22k_ft_in1k,32,80,0.0001</a></strong> to <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hoppure-/pl-migration/runs/qv19z0sy' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration/runs/qv19z0sy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if CFS['MODEL'] in model_family['resnet']:\n",
    "    norm_mean = [0.485, 0.456, 0.406]\n",
    "    norm_std = [0.229, 0.224, 0.225]\n",
    "else:\n",
    "    norm_mean = [0.5, 0.5, 0.5]\n",
    "    norm_std = [0.5, 0.5, 0.5]\n",
    "    \n",
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 1. 기하학적 변환 (Geometric Transformations)\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=0.2, p=0.5),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5)\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 2. 공간적 변형 (Spatial Transformations)\n",
    "    A.OneOf([\n",
    "        A.RandomCrop(height=int(CFS[\"IMG_SIZE\"]*0.9), width=int(CFS[\"IMG_SIZE\"]*0.9), p=0.7),\n",
    "        A.RandomResizedCrop(size=(CFS[\"IMG_SIZE\"], CFS[\"IMG_SIZE\"]), scale=(0.8, 1.0), p=0.3),\n",
    "        A.Transpose(p=0.3), \n",
    "        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 3. 색상 변환 (Color Transformations)\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "        A.CLAHE(clip_limit=4.0, p=0.2),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 4. 노이즈 및 블러 (Noise & Blur)\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), mean=0.0, per_channel=True, p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "        A.MotionBlur(blur_limit=7, p=0.3),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 5. 고급 증강 기법 (Advanced Augmentations)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, fill_value=0, p=0.5), # cutout\n",
    "        A.RandomSunFlare(src_radius=100, p=0.1),\n",
    "        A.RandomShadow(num_shadows_lower=1, num_shadows_upper=3, p=0.2)\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 6. 최종 전처리\n",
    "    A.Resize(CFS[\"IMG_SIZE\"], CFS['IMG_SIZE']),\n",
    "    A.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(CFS[\"IMG_SIZE\"], CFS['IMG_SIZE']),\n",
    "    A.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# WandB에 로깅\n",
    "wandb_logger.experiment.config[\"train_transform\"] = str(trn_transform)\n",
    "wandb_logger.experiment.config[\"test_transform\"] = str(tst_transform)\n",
    "\n",
    "\n",
    "# print(transform_str)\n",
    "# WandB에 파라미터 로깅\n",
    "# wandb_logger.experiment.config[\"train_transform\"] = get_transform_params(trn_transform)\n",
    "# wandb_logger.experiment.config[\"test_transform\"] = get_transform_params(tst_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f677c4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1e505632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04246cec",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a956a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, data_path, train_transform, test_transform, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.train_transform = train_transform\n",
    "        self.test_transform = test_transform\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = ImageDataset(\n",
    "                csv=os.path.join(self.data_path, \"train.csv\"),\n",
    "                path=os.path.join(self.data_path, \"train\"),\n",
    "                transform=self.train_transform\n",
    "            )\n",
    "            \n",
    "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
    "            self.test_dataset = ImageDataset(\n",
    "                csv=os.path.join(self.data_path, \"sample_submission.csv\"),\n",
    "                path=os.path.join(self.data_path, \"test\"),\n",
    "                transform=self.test_transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return self.test_dataloader()\n",
    "    \n",
    "datamodule = DataModule(data_path='../data/',\n",
    "    train_transform=trn_transform,\n",
    "    test_transform=tst_transform,\n",
    "    batch_size=CFS['BATCH_SIZE'],\n",
    "    num_workers=CFS['NUM_WORKERS']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9cb064",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "75700f29",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LightningModel(LightningModule):\n",
    "    def __init__(self, model_name, num_classes, lr):  \n",
    "        super().__init__()\n",
    "\n",
    "        self.model = timm.create_model(model_name=model_name, \n",
    "                                       pretrained=True,\n",
    "                                       num_classes=num_classes)\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.train_preds = []      # 예측값 저장\n",
    "        self.train_targets = []    # 타겟 저장\n",
    "        self.train_losses = []     # 배치별 손실 저장\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1)\n",
    "        \n",
    "        # 배치 단위 로깅\n",
    "        self.log('train_loss_step', loss, prog_bar=True)\n",
    "        \n",
    "        # 에포크 종료 시 메트릭 계산을 위한 데이터 수집\n",
    "        self.train_preds.append(pred.detach().cpu())\n",
    "        self.train_targets.append(y.detach().cpu())\n",
    "        self.train_losses.append(loss.detach().cpu())  # 손실 추가 저장\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # 전체 에포크 데이터 수집\n",
    "        all_preds = torch.cat(self.train_preds)\n",
    "        all_targets = torch.cat(self.train_targets)\n",
    "        \n",
    "        # 에포크 평균 손실 계산\n",
    "        epoch_loss = torch.stack(self.train_losses).mean()  # 중요!\n",
    "        \n",
    "        # 메트릭 계산\n",
    "        epoch_acc = accuracy_score(all_targets.numpy(), all_preds.numpy())\n",
    "        epoch_f1 = f1_score(all_targets.numpy(), all_preds.numpy(), average='macro')\n",
    "        \n",
    "        # 로깅 (epoch_loss 포함)\n",
    "        self.log('train_loss', epoch_loss, prog_bar=True)\n",
    "        self.log('train_acc', epoch_acc, prog_bar=True)\n",
    "        self.log('train_f1', epoch_f1, prog_bar=True)\n",
    "        \n",
    "        # 다음 에포크를 위해 리셋\n",
    "        self.train_preds.clear()\n",
    "        self.train_targets.clear()\n",
    "        self.train_losses.clear()  # 손실 리스트 초기화\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch      \n",
    "        y_hat = self(x)\n",
    "        return y_hat.argmax(dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.1, patience=5\n",
    "    #       )\n",
    "    #        return {\n",
    "    #           \"optimizer\": optimizer,\n",
    "    #           \"lr_scheduler\": {\n",
    "    #               \"scheduler\": scheduler,\n",
    "    #               \"monitor\": \"val_loss\"  # 검증 손실 기반\n",
    "    #           }\n",
    "    #       }\n",
    "        return optimizer\n",
    "\n",
    "lightning_model = LightningModel(CFS['MODEL'], num_classes, CFS[\"LR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60799932",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5569ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type     | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | model | ConvNeXt | 87.6 M | train\n",
      "-------------------------------------------\n",
      "87.6 M    Trainable params\n",
      "0         Non-trainable params\n",
      "87.6 M    Total params\n",
      "350.336   Total estimated model params size (MB)\n",
      "465       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "14a2f4f3e8d94737951339eb00ce4b0f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=80` reached.\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▄▄▄▄▄▄▄▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇███</td></tr><tr><td>train_acc</td><td>▁▄▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇█▇██████▇██████████████</td></tr><tr><td>train_f1</td><td>▁▁▁▂▄▄▄▄▅▄▅▅▆▆▆▅▆▅▆▇▇▆▆▇▇▇▇▇█▇▇▇▇▇█████▇</td></tr><tr><td>train_loss</td><td>▇▇█▄▄▄▄▄▄▄▃▃▃▃▃▄▄▃▂▃▂▂▃▂▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▂</td></tr><tr><td>train_loss_step</td><td>▂▁▃█▅▁▁▂▂▁▁▃▄▁▅▄▁▁▂▃▁▁▁▂▁▁▁▁▂▂▁▁▁▃▂▁▃▁▂▁</td></tr><tr><td>trainer/global_step</td><td>▁▁▂▂▂▂▂▂▂▃▃▃▃▃▃▃▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▆▆▇█████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>79</td></tr><tr><td>train_acc</td><td>0.9293</td></tr><tr><td>train_f1</td><td>0.92387</td></tr><tr><td>train_loss</td><td>0.22081</td></tr><tr><td>train_loss_step</td><td>0.00107</td></tr><tr><td>trainer/global_step</td><td>3999</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">convnext_base.fb_in22k_ft_in1k,32,80,0.0001</strong> at: <a href='https://wandb.ai/hoppure-/pl-migration/runs/qv19z0sy' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration/runs/qv19z0sy</a><br> View project at: <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250703_163246-qv19z0sy/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 트레이너 설정\n",
    "trainer = Trainer(\n",
    "    max_epochs=CFS[\"EPOCHS\"],\n",
    "    accelerator='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=\"auto\",\n",
    "    logger=wandb_logger,\n",
    "    # callbacks=[\n",
    "    #     pl.callbacks.ModelCheckpoint(\n",
    "    #         dirpath=\"checkpoints/\",\n",
    "    #         filename=\"{epoch}-{val_loss:.2f}\",\n",
    "    #         save_top_k=3,\n",
    "    #         monitor=\"val_loss\"  # 검증 데이터 있을 때만 유효\n",
    "    #     )\n",
    "    # ]\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    datamodule=datamodule\n",
    ")\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f16ad1",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2cd1f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "/data/ephemeral/home/.pyenv/versions/3.12.10/envs/py12/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:425: The 'predict_dataloader' does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` to `num_workers=47` in the `DataLoader` to improve performance.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fb9c42d8dcb4679841c5f343e10dd0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(\n",
    "    model=lightning_model, \n",
    "    datamodule=datamodule\n",
    ")\n",
    "\n",
    "# 4. 결과 처리\n",
    "all_preds = torch.cat(predictions).cpu().numpy()  # [n_samples]\n",
    "# 샘플 제출 파일 로드\n",
    "submission = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "# 예측값으로 타겟 열 업데이트\n",
    "submission[\"target\"] = all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dce5d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498070f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0252388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55108380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f73e5887",
   "metadata": {},
   "source": [
    "# 모델저장, 불러오기 - 작업중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# 체크포인트 콜백 설정\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",               # 저장 경로\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",    # 파일명 형식\n",
    "    save_top_k=2,                         # 상위 2개 모델 저장\n",
    "    monitor=\"train_loss\",                   # 모니터링 지표\n",
    "    mode=\"min\",                           # 최소화 대상\n",
    "    save_weights_only=False               # 전체 상태 저장 (권장)\n",
    ")\n",
    "\n",
    "# 트레이너에 콜백 추가\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=CFS['EPOCHS'],\n",
    "    logger=wandb_logger\n",
    ")\n",
    "\n",
    "# 특정 지점에서 수동 저장\n",
    "trainer.save_checkpoint(\"manual_save.ckpt\")\n",
    "\n",
    "# 모델 아키텍처 초기화\n",
    "loaded_model = LightningModel.load_from_checkpoint(\n",
    "    checkpoint_path=\"checkpoints/epoch=10-val_loss=0.32.ckpt\",\n",
    "    model_name=CFS['MODEL'],\n",
    "    num_classes=num_classes,\n",
    "    lr=CFS['LR']\n",
    ")\n",
    "\n",
    "# 예측 실행\n",
    "predictions = trainer.predict(model=loaded_model, datamodule=datamodule)\n",
    "\n",
    "# 이전 체크포인트에서 학습 재개\n",
    "trainer = Trainer(resume_from_checkpoint=\"checkpoints/last.ckpt\")\n",
    "trainer.fit(loaded_model, datamodule=datamodule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
