{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cb390275",
   "metadata": {},
   "source": [
    "# import"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a535a302",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "72e02795",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import timm\n",
    "import wandb\n",
    "import torch\n",
    "import albumentations as A\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch.nn.functional as F\n",
    "from augraphy import *\n",
    "from pytorch_lightning import LightningModule, Trainer, LightningDataModule\n",
    "from pytorch_lightning.loggers import WandbLogger\n",
    "from albumentations.core.transforms_interface import ImageOnlyTransform\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from torch.optim import Adam\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d62d501",
   "metadata": {},
   "source": [
    "# Configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "403efce8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">vit_huge_patch16_224,8,100,1e-05</strong> at: <a href='https://wandb.ai/hoppure-/pl-migration/runs/m0atumoo' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration/runs/m0atumoo</a><br> View project at: <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250704_222724-m0atumoo/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "11f1e208",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 시드를 고정합니다.\n",
    "SEED = 42\n",
    "os.environ['PYTHONHASHSEED'] = str(SEED)\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.cuda.manual_seed_all(SEED)\n",
    "torch.backends.cudnn.benchmark = True\n",
    "\n",
    "# device\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# data config\n",
    "data_path = '../data/'\n",
    "\n",
    "# model config\n",
    "model_list = {\n",
    "    1 : 'resnet34',\n",
    "    2 : 'resnet50',\n",
    "    3 : 'resnet101',\n",
    "    4 : 'resnet152',\n",
    "    6 : 'vit_small_patch16_224',\n",
    "    5 : 'vit_base_patch16_224',\n",
    "    7 : 'convnext_base.fb_in22k_ft_in1k',\n",
    "    8 : 'vit_large_patch16_224',\n",
    "    9 : 'convnextv2_huge.fcmae_ft_in1k'\t, # Out of Memory\n",
    "    10 : 'convnext_large.fb_in22k_ft_in1k', \n",
    "    11 : \"convnextv2_base.fcmae_ft_in1k\",\n",
    "    12 : 'convnext_base.fb_in22k_ft_in1k_384',\n",
    "    13 : 'vit_huge_patch14_224'\t\n",
    "\n",
    "}\n",
    "\n",
    "model_family = {\"resnet\" : [model_list[1],\n",
    "                            model_list[2],\n",
    "                            model_list[3],\n",
    "                            model_list[4],\n",
    "                            model_list[7],\n",
    "                            model_list[9],\n",
    "                            model_list[10],\n",
    "                            model_list[11],\n",
    "                            model_list[12],],\n",
    "                \"vit\" : [model_list[6],\n",
    "                         model_list[5],\n",
    "                         model_list[8],\n",
    "                         model_list[13]]\n",
    "                            }\n",
    "\n",
    "num_classes=17\n",
    "\n",
    "# training config\n",
    "\n",
    "CFS={\"MODEL\" : model_list[13],\n",
    "    \"IMG_SIZE\" : 224,\n",
    "     \"LR\" : 1e-5,\n",
    "    'EPOCHS' : 100,\n",
    "    'BATCH_SIZE' : 8,\n",
    "    \"NUM_WORKERS\" : 8,}\n",
    "\n",
    "wandb_logger = WandbLogger(\n",
    "    project=\"pl-migration\",\n",
    "    name=f\"{CFS['MODEL']},{CFS['BATCH_SIZE']},{CFS['EPOCHS']},{CFS['LR']}\",\n",
    "    config=CFS,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "30f17d1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['bat_resnext26ts', 'beit_base_patch16_224', 'beit_base_patch16_384', 'beit_large_patch16_224', 'beit_large_patch16_384', 'beit_large_patch16_512', 'beitv2_base_patch16_224', 'beitv2_large_patch16_224', 'botnet26t_256', 'botnet50ts_256', 'caformer_b36', 'caformer_m36', 'caformer_s18', 'caformer_s36', 'cait_m36_384', 'cait_m48_448', 'cait_s24_224', 'cait_s24_384', 'cait_s36_384', 'cait_xs24_384', 'cait_xxs24_224', 'cait_xxs24_384', 'cait_xxs36_224', 'cait_xxs36_384', 'coat_lite_medium', 'coat_lite_medium_384', 'coat_lite_mini', 'coat_lite_small', 'coat_lite_tiny', 'coat_mini', 'coat_small', 'coat_tiny', 'coatnet_0_224', 'coatnet_0_rw_224', 'coatnet_1_224', 'coatnet_1_rw_224', 'coatnet_2_224', 'coatnet_2_rw_224', 'coatnet_3_224', 'coatnet_3_rw_224', 'coatnet_4_224', 'coatnet_5_224', 'coatnet_bn_0_rw_224', 'coatnet_nano_cc_224', 'coatnet_nano_rw_224', 'coatnet_pico_rw_224', 'coatnet_rmlp_0_rw_224', 'coatnet_rmlp_1_rw2_224', 'coatnet_rmlp_1_rw_224', 'coatnet_rmlp_2_rw_224', 'coatnet_rmlp_2_rw_384', 'coatnet_rmlp_3_rw_224', 'coatnet_rmlp_nano_rw_224', 'coatnext_nano_rw_224', 'convformer_b36', 'convformer_m36', 'convformer_s18', 'convformer_s36', 'convit_base', 'convit_small', 'convit_tiny', 'convmixer_768_32', 'convmixer_1024_20_ks9_p14', 'convmixer_1536_20', 'convnext_atto', 'convnext_atto_ols', 'convnext_base', 'convnext_femto', 'convnext_femto_ols', 'convnext_large', 'convnext_large_mlp', 'convnext_nano', 'convnext_nano_ols', 'convnext_pico', 'convnext_pico_ols', 'convnext_small', 'convnext_tiny', 'convnext_tiny_hnf', 'convnext_xlarge', 'convnext_xxlarge', 'convnextv2_atto', 'convnextv2_base', 'convnextv2_femto', 'convnextv2_huge', 'convnextv2_large', 'convnextv2_nano', 'convnextv2_pico', 'convnextv2_small', 'convnextv2_tiny', 'crossvit_9_240', 'crossvit_9_dagger_240', 'crossvit_15_240', 'crossvit_15_dagger_240', 'crossvit_15_dagger_408', 'crossvit_18_240', 'crossvit_18_dagger_240', 'crossvit_18_dagger_408', 'crossvit_base_240', 'crossvit_small_240', 'crossvit_tiny_240', 'cs3darknet_focus_l', 'cs3darknet_focus_m', 'cs3darknet_focus_s', 'cs3darknet_focus_x', 'cs3darknet_l', 'cs3darknet_m', 'cs3darknet_s', 'cs3darknet_x', 'cs3edgenet_x', 'cs3se_edgenet_x', 'cs3sedarknet_l', 'cs3sedarknet_x', 'cs3sedarknet_xdw', 'cspdarknet53', 'cspresnet50', 'cspresnet50d', 'cspresnet50w', 'cspresnext50', 'darknet17', 'darknet21', 'darknet53', 'darknetaa53', 'davit_base', 'davit_giant', 'davit_huge', 'davit_large', 'davit_small', 'davit_tiny', 'deit3_base_patch16_224', 'deit3_base_patch16_384', 'deit3_huge_patch14_224', 'deit3_large_patch16_224', 'deit3_large_patch16_384', 'deit3_medium_patch16_224', 'deit3_small_patch16_224', 'deit3_small_patch16_384', 'deit_base_distilled_patch16_224', 'deit_base_distilled_patch16_384', 'deit_base_patch16_224', 'deit_base_patch16_384', 'deit_small_distilled_patch16_224', 'deit_small_patch16_224', 'deit_tiny_distilled_patch16_224', 'deit_tiny_patch16_224', 'densenet121', 'densenet161', 'densenet169', 'densenet201', 'densenet264d', 'densenetblur121d', 'dla34', 'dla46_c', 'dla46x_c', 'dla60', 'dla60_res2net', 'dla60_res2next', 'dla60x', 'dla60x_c', 'dla102', 'dla102x', 'dla102x2', 'dla169', 'dm_nfnet_f0', 'dm_nfnet_f1', 'dm_nfnet_f2', 'dm_nfnet_f3', 'dm_nfnet_f4', 'dm_nfnet_f5', 'dm_nfnet_f6', 'dpn48b', 'dpn68', 'dpn68b', 'dpn92', 'dpn98', 'dpn107', 'dpn131', 'eca_botnext26ts_256', 'eca_halonext26ts', 'eca_nfnet_l0', 'eca_nfnet_l1', 'eca_nfnet_l2', 'eca_nfnet_l3', 'eca_resnet33ts', 'eca_resnext26ts', 'eca_vovnet39b', 'ecaresnet26t', 'ecaresnet50d', 'ecaresnet50d_pruned', 'ecaresnet50t', 'ecaresnet101d', 'ecaresnet101d_pruned', 'ecaresnet200d', 'ecaresnet269d', 'ecaresnetlight', 'ecaresnext26t_32x4d', 'ecaresnext50t_32x4d', 'edgenext_base', 'edgenext_small', 'edgenext_small_rw', 'edgenext_x_small', 'edgenext_xx_small', 'efficientformer_l1', 'efficientformer_l3', 'efficientformer_l7', 'efficientformerv2_l', 'efficientformerv2_s0', 'efficientformerv2_s1', 'efficientformerv2_s2', 'efficientnet_b0', 'efficientnet_b0_g8_gn', 'efficientnet_b0_g16_evos', 'efficientnet_b0_gn', 'efficientnet_b1', 'efficientnet_b1_pruned', 'efficientnet_b2', 'efficientnet_b2_pruned', 'efficientnet_b3', 'efficientnet_b3_g8_gn', 'efficientnet_b3_gn', 'efficientnet_b3_pruned', 'efficientnet_b4', 'efficientnet_b5', 'efficientnet_b6', 'efficientnet_b7', 'efficientnet_b8', 'efficientnet_cc_b0_4e', 'efficientnet_cc_b0_8e', 'efficientnet_cc_b1_8e', 'efficientnet_el', 'efficientnet_el_pruned', 'efficientnet_em', 'efficientnet_es', 'efficientnet_es_pruned', 'efficientnet_l2', 'efficientnet_lite0', 'efficientnet_lite1', 'efficientnet_lite2', 'efficientnet_lite3', 'efficientnet_lite4', 'efficientnetv2_l', 'efficientnetv2_m', 'efficientnetv2_rw_m', 'efficientnetv2_rw_s', 'efficientnetv2_rw_t', 'efficientnetv2_s', 'efficientnetv2_xl', 'efficientvit_b0', 'efficientvit_b1', 'efficientvit_b2', 'efficientvit_b3', 'efficientvit_l1', 'efficientvit_l2', 'efficientvit_l3', 'efficientvit_m0', 'efficientvit_m1', 'efficientvit_m2', 'efficientvit_m3', 'efficientvit_m4', 'efficientvit_m5', 'ese_vovnet19b_dw', 'ese_vovnet19b_slim', 'ese_vovnet19b_slim_dw', 'ese_vovnet39b', 'ese_vovnet39b_evos', 'ese_vovnet57b', 'ese_vovnet99b', 'eva02_base_patch14_224', 'eva02_base_patch14_448', 'eva02_base_patch16_clip_224', 'eva02_enormous_patch14_clip_224', 'eva02_large_patch14_224', 'eva02_large_patch14_448', 'eva02_large_patch14_clip_224', 'eva02_large_patch14_clip_336', 'eva02_small_patch14_224', 'eva02_small_patch14_336', 'eva02_tiny_patch14_224', 'eva02_tiny_patch14_336', 'eva_giant_patch14_224', 'eva_giant_patch14_336', 'eva_giant_patch14_560', 'eva_giant_patch14_clip_224', 'eva_large_patch14_196', 'eva_large_patch14_336', 'fastvit_ma36', 'fastvit_s12', 'fastvit_sa12', 'fastvit_sa24', 'fastvit_sa36', 'fastvit_t8', 'fastvit_t12', 'fbnetc_100', 'fbnetv3_b', 'fbnetv3_d', 'fbnetv3_g', 'flexivit_base', 'flexivit_large', 'flexivit_small', 'focalnet_base_lrf', 'focalnet_base_srf', 'focalnet_huge_fl3', 'focalnet_huge_fl4', 'focalnet_large_fl3', 'focalnet_large_fl4', 'focalnet_small_lrf', 'focalnet_small_srf', 'focalnet_tiny_lrf', 'focalnet_tiny_srf', 'focalnet_xlarge_fl3', 'focalnet_xlarge_fl4', 'gc_efficientnetv2_rw_t', 'gcresnet33ts', 'gcresnet50t', 'gcresnext26ts', 'gcresnext50ts', 'gcvit_base', 'gcvit_small', 'gcvit_tiny', 'gcvit_xtiny', 'gcvit_xxtiny', 'gernet_l', 'gernet_m', 'gernet_s', 'ghostnet_050', 'ghostnet_100', 'ghostnet_130', 'ghostnetv2_100', 'ghostnetv2_130', 'ghostnetv2_160', 'gmixer_12_224', 'gmixer_24_224', 'gmlp_b16_224', 'gmlp_s16_224', 'gmlp_ti16_224', 'halo2botnet50ts_256', 'halonet26t', 'halonet50ts', 'halonet_h1', 'haloregnetz_b', 'hardcorenas_a', 'hardcorenas_b', 'hardcorenas_c', 'hardcorenas_d', 'hardcorenas_e', 'hardcorenas_f', 'hgnet_base', 'hgnet_small', 'hgnet_tiny', 'hgnetv2_b0', 'hgnetv2_b1', 'hgnetv2_b2', 'hgnetv2_b3', 'hgnetv2_b4', 'hgnetv2_b5', 'hgnetv2_b6', 'hiera_base_224', 'hiera_base_plus_224', 'hiera_huge_224', 'hiera_large_224', 'hiera_small_224', 'hiera_tiny_224', 'hrnet_w18', 'hrnet_w18_small', 'hrnet_w18_small_v2', 'hrnet_w18_ssld', 'hrnet_w30', 'hrnet_w32', 'hrnet_w40', 'hrnet_w44', 'hrnet_w48', 'hrnet_w48_ssld', 'hrnet_w64', 'inception_next_base', 'inception_next_small', 'inception_next_tiny', 'inception_resnet_v2', 'inception_v3', 'inception_v4', 'lambda_resnet26rpt_256', 'lambda_resnet26t', 'lambda_resnet50ts', 'lamhalobotnet50ts_256', 'lcnet_035', 'lcnet_050', 'lcnet_075', 'lcnet_100', 'lcnet_150', 'legacy_senet154', 'legacy_seresnet18', 'legacy_seresnet34', 'legacy_seresnet50', 'legacy_seresnet101', 'legacy_seresnet152', 'legacy_seresnext26_32x4d', 'legacy_seresnext50_32x4d', 'legacy_seresnext101_32x4d', 'legacy_xception', 'levit_128', 'levit_128s', 'levit_192', 'levit_256', 'levit_256d', 'levit_384', 'levit_384_s8', 'levit_512', 'levit_512_s8', 'levit_512d', 'levit_conv_128', 'levit_conv_128s', 'levit_conv_192', 'levit_conv_256', 'levit_conv_256d', 'levit_conv_384', 'levit_conv_384_s8', 'levit_conv_512', 'levit_conv_512_s8', 'levit_conv_512d', 'maxvit_base_tf_224', 'maxvit_base_tf_384', 'maxvit_base_tf_512', 'maxvit_large_tf_224', 'maxvit_large_tf_384', 'maxvit_large_tf_512', 'maxvit_nano_rw_256', 'maxvit_pico_rw_256', 'maxvit_rmlp_base_rw_224', 'maxvit_rmlp_base_rw_384', 'maxvit_rmlp_nano_rw_256', 'maxvit_rmlp_pico_rw_256', 'maxvit_rmlp_small_rw_224', 'maxvit_rmlp_small_rw_256', 'maxvit_rmlp_tiny_rw_256', 'maxvit_small_tf_224', 'maxvit_small_tf_384', 'maxvit_small_tf_512', 'maxvit_tiny_pm_256', 'maxvit_tiny_rw_224', 'maxvit_tiny_rw_256', 'maxvit_tiny_tf_224', 'maxvit_tiny_tf_384', 'maxvit_tiny_tf_512', 'maxvit_xlarge_tf_224', 'maxvit_xlarge_tf_384', 'maxvit_xlarge_tf_512', 'maxxvit_rmlp_nano_rw_256', 'maxxvit_rmlp_small_rw_256', 'maxxvit_rmlp_tiny_rw_256', 'maxxvitv2_nano_rw_256', 'maxxvitv2_rmlp_base_rw_224', 'maxxvitv2_rmlp_base_rw_384', 'maxxvitv2_rmlp_large_rw_224', 'mixer_b16_224', 'mixer_b32_224', 'mixer_l16_224', 'mixer_l32_224', 'mixer_s16_224', 'mixer_s32_224', 'mixnet_l', 'mixnet_m', 'mixnet_s', 'mixnet_xl', 'mixnet_xxl', 'mnasnet_050', 'mnasnet_075', 'mnasnet_100', 'mnasnet_140', 'mnasnet_small', 'mobilenetv2_035', 'mobilenetv2_050', 'mobilenetv2_075', 'mobilenetv2_100', 'mobilenetv2_110d', 'mobilenetv2_120d', 'mobilenetv2_140', 'mobilenetv3_large_075', 'mobilenetv3_large_100', 'mobilenetv3_rw', 'mobilenetv3_small_050', 'mobilenetv3_small_075', 'mobilenetv3_small_100', 'mobileone_s0', 'mobileone_s1', 'mobileone_s2', 'mobileone_s3', 'mobileone_s4', 'mobilevit_s', 'mobilevit_xs', 'mobilevit_xxs', 'mobilevitv2_050', 'mobilevitv2_075', 'mobilevitv2_100', 'mobilevitv2_125', 'mobilevitv2_150', 'mobilevitv2_175', 'mobilevitv2_200', 'mvitv2_base', 'mvitv2_base_cls', 'mvitv2_huge_cls', 'mvitv2_large', 'mvitv2_large_cls', 'mvitv2_small', 'mvitv2_small_cls', 'mvitv2_tiny', 'nasnetalarge', 'nest_base', 'nest_base_jx', 'nest_small', 'nest_small_jx', 'nest_tiny', 'nest_tiny_jx', 'nextvit_base', 'nextvit_large', 'nextvit_small', 'nf_ecaresnet26', 'nf_ecaresnet50', 'nf_ecaresnet101', 'nf_regnet_b0', 'nf_regnet_b1', 'nf_regnet_b2', 'nf_regnet_b3', 'nf_regnet_b4', 'nf_regnet_b5', 'nf_resnet26', 'nf_resnet50', 'nf_resnet101', 'nf_seresnet26', 'nf_seresnet50', 'nf_seresnet101', 'nfnet_f0', 'nfnet_f1', 'nfnet_f2', 'nfnet_f3', 'nfnet_f4', 'nfnet_f5', 'nfnet_f6', 'nfnet_f7', 'nfnet_l0', 'pit_b_224', 'pit_b_distilled_224', 'pit_s_224', 'pit_s_distilled_224', 'pit_ti_224', 'pit_ti_distilled_224', 'pit_xs_224', 'pit_xs_distilled_224', 'pnasnet5large', 'poolformer_m36', 'poolformer_m48', 'poolformer_s12', 'poolformer_s24', 'poolformer_s36', 'poolformerv2_m36', 'poolformerv2_m48', 'poolformerv2_s12', 'poolformerv2_s24', 'poolformerv2_s36', 'pvt_v2_b0', 'pvt_v2_b1', 'pvt_v2_b2', 'pvt_v2_b2_li', 'pvt_v2_b3', 'pvt_v2_b4', 'pvt_v2_b5', 'regnetv_040', 'regnetv_064', 'regnetx_002', 'regnetx_004', 'regnetx_004_tv', 'regnetx_006', 'regnetx_008', 'regnetx_016', 'regnetx_032', 'regnetx_040', 'regnetx_064', 'regnetx_080', 'regnetx_120', 'regnetx_160', 'regnetx_320', 'regnety_002', 'regnety_004', 'regnety_006', 'regnety_008', 'regnety_008_tv', 'regnety_016', 'regnety_032', 'regnety_040', 'regnety_040_sgn', 'regnety_064', 'regnety_080', 'regnety_080_tv', 'regnety_120', 'regnety_160', 'regnety_320', 'regnety_640', 'regnety_1280', 'regnety_2560', 'regnetz_005', 'regnetz_040', 'regnetz_040_h', 'regnetz_b16', 'regnetz_b16_evos', 'regnetz_c16', 'regnetz_c16_evos', 'regnetz_d8', 'regnetz_d8_evos', 'regnetz_d32', 'regnetz_e8', 'repghostnet_050', 'repghostnet_058', 'repghostnet_080', 'repghostnet_100', 'repghostnet_111', 'repghostnet_130', 'repghostnet_150', 'repghostnet_200', 'repvgg_a0', 'repvgg_a1', 'repvgg_a2', 'repvgg_b0', 'repvgg_b1', 'repvgg_b1g4', 'repvgg_b2', 'repvgg_b2g4', 'repvgg_b3', 'repvgg_b3g4', 'repvgg_d2se', 'repvit_m0_9', 'repvit_m1', 'repvit_m1_0', 'repvit_m1_1', 'repvit_m1_5', 'repvit_m2', 'repvit_m2_3', 'repvit_m3', 'res2net50_14w_8s', 'res2net50_26w_4s', 'res2net50_26w_6s', 'res2net50_26w_8s', 'res2net50_48w_2s', 'res2net50d', 'res2net101_26w_4s', 'res2net101d', 'res2next50', 'resmlp_12_224', 'resmlp_24_224', 'resmlp_36_224', 'resmlp_big_24_224', 'resnest14d', 'resnest26d', 'resnest50d', 'resnest50d_1s4x24d', 'resnest50d_4s2x40d', 'resnest101e', 'resnest200e', 'resnest269e', 'resnet10t', 'resnet14t', 'resnet18', 'resnet18d', 'resnet26', 'resnet26d', 'resnet26t', 'resnet32ts', 'resnet33ts', 'resnet34', 'resnet34d', 'resnet50', 'resnet50_gn', 'resnet50c', 'resnet50d', 'resnet50s', 'resnet50t', 'resnet51q', 'resnet61q', 'resnet101', 'resnet101c', 'resnet101d', 'resnet101s', 'resnet152', 'resnet152c', 'resnet152d', 'resnet152s', 'resnet200', 'resnet200d', 'resnetaa34d', 'resnetaa50', 'resnetaa50d', 'resnetaa101d', 'resnetblur18', 'resnetblur50', 'resnetblur50d', 'resnetblur101d', 'resnetrs50', 'resnetrs101', 'resnetrs152', 'resnetrs200', 'resnetrs270', 'resnetrs350', 'resnetrs420', 'resnetv2_50', 'resnetv2_50d', 'resnetv2_50d_evos', 'resnetv2_50d_frn', 'resnetv2_50d_gn', 'resnetv2_50t', 'resnetv2_50x1_bit', 'resnetv2_50x3_bit', 'resnetv2_101', 'resnetv2_101d', 'resnetv2_101x1_bit', 'resnetv2_101x3_bit', 'resnetv2_152', 'resnetv2_152d', 'resnetv2_152x2_bit', 'resnetv2_152x4_bit', 'resnext26ts', 'resnext50_32x4d', 'resnext50d_32x4d', 'resnext101_32x4d', 'resnext101_32x8d', 'resnext101_32x16d', 'resnext101_32x32d', 'resnext101_64x4d', 'rexnet_100', 'rexnet_130', 'rexnet_150', 'rexnet_200', 'rexnet_300', 'rexnetr_100', 'rexnetr_130', 'rexnetr_150', 'rexnetr_200', 'rexnetr_300', 'samvit_base_patch16', 'samvit_base_patch16_224', 'samvit_huge_patch16', 'samvit_large_patch16', 'sebotnet33ts_256', 'sedarknet21', 'sehalonet33ts', 'selecsls42', 'selecsls42b', 'selecsls60', 'selecsls60b', 'selecsls84', 'semnasnet_050', 'semnasnet_075', 'semnasnet_100', 'semnasnet_140', 'senet154', 'sequencer2d_l', 'sequencer2d_m', 'sequencer2d_s', 'seresnet18', 'seresnet33ts', 'seresnet34', 'seresnet50', 'seresnet50t', 'seresnet101', 'seresnet152', 'seresnet152d', 'seresnet200d', 'seresnet269d', 'seresnetaa50d', 'seresnext26d_32x4d', 'seresnext26t_32x4d', 'seresnext26ts', 'seresnext50_32x4d', 'seresnext101_32x4d', 'seresnext101_32x8d', 'seresnext101_64x4d', 'seresnext101d_32x8d', 'seresnextaa101d_32x8d', 'seresnextaa201d_32x8d', 'skresnet18', 'skresnet34', 'skresnet50', 'skresnet50d', 'skresnext50_32x4d', 'spnasnet_100', 'swin_base_patch4_window7_224', 'swin_base_patch4_window12_384', 'swin_large_patch4_window7_224', 'swin_large_patch4_window12_384', 'swin_s3_base_224', 'swin_s3_small_224', 'swin_s3_tiny_224', 'swin_small_patch4_window7_224', 'swin_tiny_patch4_window7_224', 'swinv2_base_window8_256', 'swinv2_base_window12_192', 'swinv2_base_window12to16_192to256', 'swinv2_base_window12to24_192to384', 'swinv2_base_window16_256', 'swinv2_cr_base_224', 'swinv2_cr_base_384', 'swinv2_cr_base_ns_224', 'swinv2_cr_giant_224', 'swinv2_cr_giant_384', 'swinv2_cr_huge_224', 'swinv2_cr_huge_384', 'swinv2_cr_large_224', 'swinv2_cr_large_384', 'swinv2_cr_small_224', 'swinv2_cr_small_384', 'swinv2_cr_small_ns_224', 'swinv2_cr_small_ns_256', 'swinv2_cr_tiny_224', 'swinv2_cr_tiny_384', 'swinv2_cr_tiny_ns_224', 'swinv2_large_window12_192', 'swinv2_large_window12to16_192to256', 'swinv2_large_window12to24_192to384', 'swinv2_small_window8_256', 'swinv2_small_window16_256', 'swinv2_tiny_window8_256', 'swinv2_tiny_window16_256', 'tf_efficientnet_b0', 'tf_efficientnet_b1', 'tf_efficientnet_b2', 'tf_efficientnet_b3', 'tf_efficientnet_b4', 'tf_efficientnet_b5', 'tf_efficientnet_b6', 'tf_efficientnet_b7', 'tf_efficientnet_b8', 'tf_efficientnet_cc_b0_4e', 'tf_efficientnet_cc_b0_8e', 'tf_efficientnet_cc_b1_8e', 'tf_efficientnet_el', 'tf_efficientnet_em', 'tf_efficientnet_es', 'tf_efficientnet_l2', 'tf_efficientnet_lite0', 'tf_efficientnet_lite1', 'tf_efficientnet_lite2', 'tf_efficientnet_lite3', 'tf_efficientnet_lite4', 'tf_efficientnetv2_b0', 'tf_efficientnetv2_b1', 'tf_efficientnetv2_b2', 'tf_efficientnetv2_b3', 'tf_efficientnetv2_l', 'tf_efficientnetv2_m', 'tf_efficientnetv2_s', 'tf_efficientnetv2_xl', 'tf_mixnet_l', 'tf_mixnet_m', 'tf_mixnet_s', 'tf_mobilenetv3_large_075', 'tf_mobilenetv3_large_100', 'tf_mobilenetv3_large_minimal_100', 'tf_mobilenetv3_small_075', 'tf_mobilenetv3_small_100', 'tf_mobilenetv3_small_minimal_100', 'tiny_vit_5m_224', 'tiny_vit_11m_224', 'tiny_vit_21m_224', 'tiny_vit_21m_384', 'tiny_vit_21m_512', 'tinynet_a', 'tinynet_b', 'tinynet_c', 'tinynet_d', 'tinynet_e', 'tnt_b_patch16_224', 'tnt_s_patch16_224', 'tresnet_l', 'tresnet_m', 'tresnet_v2_l', 'tresnet_xl', 'twins_pcpvt_base', 'twins_pcpvt_large', 'twins_pcpvt_small', 'twins_svt_base', 'twins_svt_large', 'twins_svt_small', 'vgg11', 'vgg11_bn', 'vgg13', 'vgg13_bn', 'vgg16', 'vgg16_bn', 'vgg19', 'vgg19_bn', 'visformer_small', 'visformer_tiny', 'vit_base_patch8_224', 'vit_base_patch14_dinov2', 'vit_base_patch14_reg4_dinov2', 'vit_base_patch16_18x2_224', 'vit_base_patch16_224', 'vit_base_patch16_224_miil', 'vit_base_patch16_384', 'vit_base_patch16_clip_224', 'vit_base_patch16_clip_384', 'vit_base_patch16_clip_quickgelu_224', 'vit_base_patch16_gap_224', 'vit_base_patch16_plus_240', 'vit_base_patch16_reg4_gap_256', 'vit_base_patch16_rope_reg1_gap_256', 'vit_base_patch16_rpn_224', 'vit_base_patch16_siglip_224', 'vit_base_patch16_siglip_256', 'vit_base_patch16_siglip_384', 'vit_base_patch16_siglip_512', 'vit_base_patch16_siglip_gap_224', 'vit_base_patch16_siglip_gap_256', 'vit_base_patch16_siglip_gap_384', 'vit_base_patch16_siglip_gap_512', 'vit_base_patch16_xp_224', 'vit_base_patch32_224', 'vit_base_patch32_384', 'vit_base_patch32_clip_224', 'vit_base_patch32_clip_256', 'vit_base_patch32_clip_384', 'vit_base_patch32_clip_448', 'vit_base_patch32_clip_quickgelu_224', 'vit_base_patch32_plus_256', 'vit_base_r26_s32_224', 'vit_base_r50_s16_224', 'vit_base_r50_s16_384', 'vit_base_resnet26d_224', 'vit_base_resnet50d_224', 'vit_betwixt_patch16_gap_256', 'vit_betwixt_patch16_reg1_gap_256', 'vit_betwixt_patch16_reg4_gap_256', 'vit_betwixt_patch16_rope_reg4_gap_256', 'vit_betwixt_patch32_clip_224', 'vit_giant_patch14_224', 'vit_giant_patch14_clip_224', 'vit_giant_patch14_dinov2', 'vit_giant_patch14_reg4_dinov2', 'vit_giant_patch16_gap_224', 'vit_gigantic_patch14_224', 'vit_gigantic_patch14_clip_224', 'vit_huge_patch14_224', 'vit_huge_patch14_clip_224', 'vit_huge_patch14_clip_336', 'vit_huge_patch14_clip_378', 'vit_huge_patch14_clip_quickgelu_224', 'vit_huge_patch14_clip_quickgelu_378', 'vit_huge_patch14_gap_224', 'vit_huge_patch14_xp_224', 'vit_huge_patch16_gap_448', 'vit_large_patch14_224', 'vit_large_patch14_clip_224', 'vit_large_patch14_clip_336', 'vit_large_patch14_clip_quickgelu_224', 'vit_large_patch14_clip_quickgelu_336', 'vit_large_patch14_dinov2', 'vit_large_patch14_reg4_dinov2', 'vit_large_patch14_xp_224', 'vit_large_patch16_224', 'vit_large_patch16_384', 'vit_large_patch16_siglip_256', 'vit_large_patch16_siglip_384', 'vit_large_patch16_siglip_gap_256', 'vit_large_patch16_siglip_gap_384', 'vit_large_patch32_224', 'vit_large_patch32_384', 'vit_large_r50_s32_224', 'vit_large_r50_s32_384', 'vit_little_patch16_reg4_gap_256', 'vit_medium_patch16_clip_224', 'vit_medium_patch16_gap_240', 'vit_medium_patch16_gap_256', 'vit_medium_patch16_gap_384', 'vit_medium_patch16_reg1_gap_256', 'vit_medium_patch16_reg4_gap_256', 'vit_medium_patch16_rope_reg1_gap_256', 'vit_medium_patch32_clip_224', 'vit_mediumd_patch16_reg4_gap_256', 'vit_mediumd_patch16_rope_reg1_gap_256', 'vit_pwee_patch16_reg1_gap_256', 'vit_relpos_base_patch16_224', 'vit_relpos_base_patch16_cls_224', 'vit_relpos_base_patch16_clsgap_224', 'vit_relpos_base_patch16_plus_240', 'vit_relpos_base_patch16_rpn_224', 'vit_relpos_base_patch32_plus_rpn_256', 'vit_relpos_medium_patch16_224', 'vit_relpos_medium_patch16_cls_224', 'vit_relpos_medium_patch16_rpn_224', 'vit_relpos_small_patch16_224', 'vit_relpos_small_patch16_rpn_224', 'vit_small_patch8_224', 'vit_small_patch14_dinov2', 'vit_small_patch14_reg4_dinov2', 'vit_small_patch16_18x2_224', 'vit_small_patch16_36x1_224', 'vit_small_patch16_224', 'vit_small_patch16_384', 'vit_small_patch32_224', 'vit_small_patch32_384', 'vit_small_r26_s32_224', 'vit_small_r26_s32_384', 'vit_small_resnet26d_224', 'vit_small_resnet50d_s16_224', 'vit_so150m_patch16_reg4_gap_256', 'vit_so150m_patch16_reg4_map_256', 'vit_so400m_patch14_siglip_224', 'vit_so400m_patch14_siglip_384', 'vit_so400m_patch14_siglip_gap_224', 'vit_so400m_patch14_siglip_gap_384', 'vit_so400m_patch14_siglip_gap_448', 'vit_so400m_patch14_siglip_gap_896', 'vit_srelpos_medium_patch16_224', 'vit_srelpos_small_patch16_224', 'vit_tiny_patch16_224', 'vit_tiny_patch16_384', 'vit_tiny_r_s16_p8_224', 'vit_tiny_r_s16_p8_384', 'vit_wee_patch16_reg1_gap_256', 'vit_xsmall_patch16_clip_224', 'volo_d1_224', 'volo_d1_384', 'volo_d2_224', 'volo_d2_384', 'volo_d3_224', 'volo_d3_448', 'volo_d4_224', 'volo_d4_448', 'volo_d5_224', 'volo_d5_448', 'volo_d5_512', 'vovnet39a', 'vovnet57a', 'wide_resnet50_2', 'wide_resnet101_2', 'xception41', 'xception41p', 'xception65', 'xception65p', 'xception71', 'xcit_large_24_p8_224', 'xcit_large_24_p8_384', 'xcit_large_24_p16_224', 'xcit_large_24_p16_384', 'xcit_medium_24_p8_224', 'xcit_medium_24_p8_384', 'xcit_medium_24_p16_224', 'xcit_medium_24_p16_384', 'xcit_nano_12_p8_224', 'xcit_nano_12_p8_384', 'xcit_nano_12_p16_224', 'xcit_nano_12_p16_384', 'xcit_small_12_p8_224', 'xcit_small_12_p8_384', 'xcit_small_12_p16_224', 'xcit_small_12_p16_384', 'xcit_small_24_p8_224', 'xcit_small_24_p8_384', 'xcit_small_24_p16_224', 'xcit_small_24_p16_384', 'xcit_tiny_12_p8_224', 'xcit_tiny_12_p8_384', 'xcit_tiny_12_p16_224', 'xcit_tiny_12_p16_384', 'xcit_tiny_24_p8_224', 'xcit_tiny_24_p8_384', 'xcit_tiny_24_p16_224', 'xcit_tiny_24_p16_384']\n"
     ]
    }
   ],
   "source": [
    "model_list = timm.list_models()\n",
    "print(model_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96b8725f",
   "metadata": {},
   "source": [
    "# Augraphy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "51377b60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.20.1"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>./wandb/run-20250704_223108-hexgpypj</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/hoppure-/pl-migration/runs/hexgpypj' target=\"_blank\">vit_huge_patch14_224,8,100,1e-05</a></strong> to <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/hoppure-/pl-migration' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/hoppure-/pl-migration/runs/hexgpypj' target=\"_blank\">https://wandb.ai/hoppure-/pl-migration/runs/hexgpypj</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ink_phase = [\n",
    "    InkBleed(\n",
    "        intensity_range=(0.5, 0.6),\n",
    "        kernel_size=random.choice([(5, 5), (3, 3)]),\n",
    "        severity=(0.2, 0.4),\n",
    "        p=0.1,\n",
    "    ),\n",
    "    BleedThrough(\n",
    "        intensity_range=(0.1, 0.3),\n",
    "        color_range=(32, 224),\n",
    "        ksize=(17, 17),\n",
    "        sigmaX=1,\n",
    "        alpha=random.uniform(0.1, 0.2),\n",
    "        offsets=(10, 20),\n",
    "        p=0.1,\n",
    "    ),\n",
    "],\n",
    "\n",
    "paper_phase = [\n",
    "    ColorPaper(\n",
    "        hue_range=(0, 255),\n",
    "        saturation_range=(10, 40),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    OneOf(\n",
    "        [\n",
    "        DelaunayTessellation(\n",
    "            n_points_range=(500, 800),\n",
    "            n_horizontal_points_range=(500, 800),\n",
    "            n_vertical_points_range=(500, 800),\n",
    "            noise_type=\"random\",\n",
    "            color_list=\"default\",\n",
    "            color_list_alternate=\"default\",\n",
    "            ),\n",
    "        PatternGenerator(\n",
    "            imgx=random.randint(256, 512),\n",
    "            imgy=random.randint(256, 512),\n",
    "            n_rotation_range=(10, 15),\n",
    "            color=\"random\",\n",
    "            alpha_range=(0.25, 0.5),\n",
    "            ),\n",
    "        VoronoiTessellation(\n",
    "            mult_range=(50, 80),\n",
    "            seed=19829813472,\n",
    "            num_cells_range=(500, 1000),\n",
    "            noise_type=\"random\",\n",
    "            background_value=(200, 255),\n",
    "            ),\n",
    "        ],\n",
    "        p=1.0,\n",
    "    ),\n",
    "    AugmentationSequence(\n",
    "        [\n",
    "            NoiseTexturize(\n",
    "                sigma_range=(3, 10),\n",
    "                turbulence_range=(2, 5),\n",
    "            ),\n",
    "            BrightnessTexturize(\n",
    "                texturize_range=(0.9, 0.99),\n",
    "                deviation=0.03,\n",
    "            ),\n",
    "        ],\n",
    "    ),\n",
    "]\n",
    "\n",
    "post_phase = [\n",
    "    OneOf(\n",
    "        [\n",
    "            DirtyDrum(\n",
    "                line_width_range=(1, 6),\n",
    "                line_concentration=random.uniform(0.05, 0.15),\n",
    "                direction=random.randint(0, 2),\n",
    "                noise_intensity=random.uniform(0.6, 0.95),\n",
    "                noise_value=(64, 224),\n",
    "                ksize=random.choice([(3, 3), (5, 5), (7, 7)]),\n",
    "                sigmaX=0,\n",
    "                p=0.2,\n",
    "            ),\n",
    "            DirtyRollers(\n",
    "                line_width_range=(2, 32),\n",
    "                scanline_type=0,\n",
    "            ),\n",
    "        ],\n",
    "        p=0.33,\n",
    "    ),\n",
    "    Folding(\n",
    "        fold_count=10,\n",
    "        fold_noise=0.0,\n",
    "        fold_angle_range = (-360,360),\n",
    "        gradient_width=(0.1, 0.2),\n",
    "        gradient_height=(0.01, 0.1),\n",
    "        backdrop_color = (0,0,0),\n",
    "        p=0.33\n",
    "    ),\n",
    "    SubtleNoise(\n",
    "        subtle_range=random.randint(5, 10),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    Jpeg(\n",
    "        quality_range=(25, 95),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    Moire(\n",
    "        moire_density = (15,20),\n",
    "        moire_blend_method = \"normal\",\n",
    "        moire_blend_alpha = 0.1,\n",
    "        p=0.33\n",
    "    ),\n",
    "    ColorShift(\n",
    "        color_shift_offset_x_range=(3, 5),\n",
    "        color_shift_offset_y_range=(3, 5),\n",
    "        color_shift_iterations=(2, 3),\n",
    "        color_shift_brightness_range=(0.9, 1.1),\n",
    "        color_shift_gaussian_kernel_range=(3, 3),\n",
    "        p=0.33\n",
    "    ),\n",
    "    Scribbles(\n",
    "        scribbles_type=\"random\",\n",
    "        scribbles_location=\"random\",\n",
    "        scribbles_size_range=(250, 600),\n",
    "        scribbles_count_range=(1, 6),\n",
    "        scribbles_thickness_range=(1, 3),\n",
    "        scribbles_brightness_change=[32, 64, 128],\n",
    "        scribbles_text=\"random\",\n",
    "        scribbles_text_font=\"random\",\n",
    "        scribbles_text_rotate_range=(0, 360),\n",
    "        scribbles_lines_stroke_count_range=(1, 6),\n",
    "        p=0.1,\n",
    "    ),\n",
    "    BadPhotoCopy(\n",
    "        noise_type=-1,\n",
    "        noise_side=\"random\",\n",
    "        noise_iteration=(1, 2),\n",
    "        noise_size=(1, 3),\n",
    "        noise_value=(128, 196),\n",
    "        noise_sparsity=(0.3, 0.6),\n",
    "        noise_concentration=(0.1, 0.6),\n",
    "        blur_noise=random.choice([True, False]),\n",
    "        blur_noise_kernel=random.choice([(3, 3), (5, 5), (7, 7)]),\n",
    "        wave_pattern=random.choice([True, False]),\n",
    "        edge_effect=random.choice([True, False]),\n",
    "        p=0.33,\n",
    "    ),\n",
    "    Faxify(\n",
    "        scale_range=(0.3, 0.6),\n",
    "        monochrome=random.choice([0, 1]),\n",
    "        monochrome_method=\"random\",\n",
    "        monochrome_arguments={},\n",
    "        halftone=random.choice([0, 1]),\n",
    "        invert=1,\n",
    "        half_kernel_size=random.choice([(1, 1), (2, 2)]),\n",
    "        angle=(0, 360),\n",
    "        sigma=(1, 3),\n",
    "        p=0.1,\n",
    "    ),\n",
    "    Geometric(\n",
    "        scale=(0.5, 1.5),\n",
    "        translation=(50, -50),\n",
    "        fliplr=1,\n",
    "        flipud=1,\n",
    "        crop=(),\n",
    "        rotate_range=(3, 5),\n",
    "        p=0.33,\n",
    "    ),\n",
    "\n",
    "]\n",
    "\n",
    "pipeline = AugraphyPipeline(ink_phase=ink_phase, paper_phase=paper_phase, post_phase=post_phase)\n",
    "\n",
    "class AugraphyTransform(ImageOnlyTransform):\n",
    "    def __init__(self, augraphy_pipeline, always_apply=False, p=0.5):\n",
    "        super().__init__(always_apply, p)\n",
    "        self.augraphy_pipeline = augraphy_pipeline\n",
    "\n",
    "    def apply(self, img, **params):\n",
    "        # NumPy → PIL 변환\n",
    "        pil_img = Image.fromarray(img)\n",
    "        # Augraphy 증강 적용\n",
    "        aug_img = self.augraphy_pipeline(pil_img)\n",
    "        # PIL → NumPy 변환\n",
    "        return np.array(aug_img)\n",
    "\n",
    "Augraphy = AugraphyTransform(augraphy_pipeline=pipeline, p=0.5)\n",
    "\n",
    "wandb_logger.experiment.config[\"Augrapy\"] = str(pipeline)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a26dc071",
   "metadata": {},
   "source": [
    "# Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e06151",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스코어가 하락한 augementation 모음\n",
    "\n",
    "# A.Affine(translate_percent={\"x\": (-0.1, 0.1), \"y\": (-0.1, 0.1)}, rotate=(-15, 15), scale=(0.9, 1.1), shear=(-10, 10), p=0.5),\n",
    "# A.Perspective(scale=(0.05, 0.1), p=0.5),\n",
    "# A.SquareSymmetry(p=0.2),\n",
    "# A.Transpose(p=0.5), \n",
    "# A.HueSaturationValue(hue_shift_limit=10, sat_shift_limit=15, val_shift_limit=10, p=0.3),\n",
    "# A.RGBShift(r_shift_limit=10, g_shift_limit=10, b_shift_limit=10, p=0.2)\n",
    "# A.ISONoise(color_shift=(0.01, 0.05), intensity=(0.1, 0.5), p=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b74e90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if CFS['MODEL'] in model_family['resnet']:\n",
    "    norm_mean = [0.485, 0.456, 0.406]\n",
    "    norm_std = [0.229, 0.224, 0.225]\n",
    "else:\n",
    "    norm_mean = [0.5, 0.5, 0.5]\n",
    "    norm_std = [0.5, 0.5, 0.5]\n",
    "    \n",
    "# augmentation을 위한 transform 코드\n",
    "trn_transform = A.Compose([\n",
    "    # 0. augraphy\n",
    "    Augraphy,\n",
    "    \n",
    "    # 1. 기하학적 변환 (Geometric Transformations)\n",
    "    A.OneOf([\n",
    "        A.ShiftScaleRotate(shift_limit=0.1, scale_limit=0.15, rotate_limit=15, p=0.5),\n",
    "        A.OpticalDistortion(distort_limit=0.2, p=0.5),\n",
    "        A.GridDistortion(num_steps=5, distort_limit=0.3, p=0.5),\n",
    "        A.HorizontalFlip(p=0.5),\n",
    "        A.VerticalFlip(p=0.5)\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 2. 공간적 변형 (Spatial Transformations)\n",
    "    A.OneOf([\n",
    "        A.RandomCrop(height=int(CFS[\"IMG_SIZE\"]*0.9), width=int(CFS[\"IMG_SIZE\"]*0.9), p=0.7),\n",
    "        A.RandomResizedCrop(size=(CFS[\"IMG_SIZE\"], CFS[\"IMG_SIZE\"]), scale=(0.8, 1.0), p=0.3),\n",
    "        A.Transpose(p=0.3), \n",
    "        A.ElasticTransform(alpha=1, sigma=50, alpha_affine=50, p=0.2),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 3. 색상 변환 (Color Transformations)\n",
    "    A.OneOf([\n",
    "        A.RandomBrightnessContrast(brightness_limit=0.3, contrast_limit=0.3, p=0.5),\n",
    "        A.RandomGamma(gamma_limit=(80, 120), p=0.3),\n",
    "        A.CLAHE(clip_limit=4.0, p=0.2),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 4. 노이즈 및 블러 (Noise & Blur)\n",
    "    A.OneOf([\n",
    "        A.GaussNoise(var_limit=(10.0, 50.0), mean=0.0, per_channel=True, p=0.4),\n",
    "        A.GaussianBlur(blur_limit=(3, 7), p=0.3),\n",
    "        A.MotionBlur(blur_limit=7, p=0.3),\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 5. 고급 증강 기법 (Advanced Augmentations)\n",
    "    A.OneOf([\n",
    "        A.CoarseDropout(max_holes=8, max_height=16, max_width=16, fill_value=0, p=0.5), # cutout\n",
    "        A.RandomSunFlare(src_radius=100, p=0.1),\n",
    "        A.RandomShadow(num_shadows_lower=1, num_shadows_upper=3, p=0.2)\n",
    "    ], p=1.0),\n",
    "    \n",
    "    # 6. 최종 전처리\n",
    "    A.Resize(CFS[\"IMG_SIZE\"], CFS['IMG_SIZE']),\n",
    "    A.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "# test image 변환을 위한 transform 코드\n",
    "tst_transform = A.Compose([\n",
    "    A.Resize(CFS[\"IMG_SIZE\"], CFS['IMG_SIZE']),\n",
    "    A.Normalize(mean=norm_mean, std=norm_std),\n",
    "    ToTensorV2(),\n",
    "])\n",
    "\n",
    "# WandB에 로깅\n",
    "wandb_logger.experiment.config[\"train_transform\"] = str(trn_transform)\n",
    "wandb_logger.experiment.config[\"test_transform\"] = str(tst_transform)\n",
    "\n",
    "# print(transform_str)\n",
    "# WandB에 파라미터 로깅\n",
    "# wandb_logger.experiment.config[\"train_transform\"] = get_transform_params(trn_transform)\n",
    "# wandb_logger.experiment.config[\"test_transform\"] = get_transform_params(tst_transform)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90f677c4",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1e505632",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터셋 클래스를 정의합니다.\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, csv, path, transform=None):\n",
    "        self.df = pd.read_csv(csv).values\n",
    "        self.path = path\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        name, target = self.df[idx]\n",
    "        img = np.array(Image.open(os.path.join(self.path, name)))\n",
    "        if self.transform:\n",
    "            img = self.transform(image=img)['image']\n",
    "        return img, target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04246cec",
   "metadata": {},
   "source": [
    "# Datamodule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3a956a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataModule(LightningDataModule):\n",
    "    def __init__(self, data_path, train_transform, test_transform, batch_size, num_workers):\n",
    "        super().__init__()\n",
    "        self.data_path = data_path\n",
    "        self.train_transform = train_transform\n",
    "        self.test_transform = test_transform\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\" or stage is None:\n",
    "            self.train_dataset = ImageDataset(\n",
    "                csv=os.path.join(self.data_path, \"train.csv\"),\n",
    "                path=os.path.join(self.data_path, \"train\"),\n",
    "                transform=self.train_transform\n",
    "            )\n",
    "            \n",
    "        if stage == \"test\" or stage == \"predict\" or stage is None:\n",
    "            self.test_dataset = ImageDataset(\n",
    "                csv=os.path.join(self.data_path, \"sample_submission.csv\"),\n",
    "                path=os.path.join(self.data_path, \"test\"),\n",
    "                transform=self.test_transform\n",
    "            )\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            pin_memory=True,\n",
    "            drop_last=False\n",
    "        )\n",
    "    \n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.test_dataset,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=0,\n",
    "            pin_memory=True\n",
    "        )\n",
    "    \n",
    "    def predict_dataloader(self):\n",
    "        return self.test_dataloader()\n",
    "    \n",
    "datamodule = DataModule(data_path='../data/',\n",
    "    train_transform=trn_transform,\n",
    "    test_transform=tst_transform,\n",
    "    batch_size=CFS['BATCH_SIZE'],\n",
    "    num_workers=CFS['NUM_WORKERS']\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c9cb064",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "75700f29",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ae365985b93845d3937b3b8dab3dd38f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.52G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class LightningModel(LightningModule):\n",
    "    def __init__(self, model_name, num_classes, lr):  \n",
    "        super().__init__()\n",
    "\n",
    "        self.model = timm.create_model(model_name=model_name, \n",
    "                                       pretrained=True,\n",
    "                                       num_classes=num_classes)\n",
    "        self.lr = lr\n",
    "        self.num_classes = num_classes\n",
    "        self.train_preds = []      # 예측값 저장\n",
    "        self.train_targets = []    # 타겟 저장\n",
    "        self.train_losses = []     # 배치별 손실 저장\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        pred = y_hat.argmax(dim=1)\n",
    "        \n",
    "        # 배치 단위 로깅\n",
    "        self.log('train_loss_step', loss, prog_bar=True)\n",
    "        \n",
    "        # 에포크 종료 시 메트릭 계산을 위한 데이터 수집\n",
    "        self.train_preds.append(pred.detach().cpu())\n",
    "        self.train_targets.append(y.detach().cpu())\n",
    "        self.train_losses.append(loss.detach().cpu())  # 손실 추가 저장\n",
    "        \n",
    "        return loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # 전체 에포크 데이터 수집\n",
    "        all_preds = torch.cat(self.train_preds)\n",
    "        all_targets = torch.cat(self.train_targets)\n",
    "        \n",
    "        # 에포크 평균 손실 계산\n",
    "        epoch_loss = torch.stack(self.train_losses).mean()  # 중요!\n",
    "        \n",
    "        # 메트릭 계산\n",
    "        epoch_acc = accuracy_score(all_targets.numpy(), all_preds.numpy())\n",
    "        epoch_f1 = f1_score(all_targets.numpy(), all_preds.numpy(), average='macro')\n",
    "        \n",
    "        # 로깅 (epoch_loss 포함)\n",
    "        self.log('train_loss', epoch_loss, prog_bar=True)\n",
    "        self.log('train_acc', epoch_acc, prog_bar=True)\n",
    "        self.log('train_f1', epoch_f1, prog_bar=True)\n",
    "        \n",
    "        # 다음 에포크를 위해 리셋\n",
    "        self.train_preds.clear()\n",
    "        self.train_targets.clear()\n",
    "        self.train_losses.clear()  # 손실 리스트 초기화\n",
    "\n",
    "    def predict_step(self, batch, batch_idx):\n",
    "        x, _ = batch      \n",
    "        y_hat = self(x)\n",
    "        return y_hat.argmax(dim=1)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = Adam(self.parameters(), lr=self.lr)\n",
    "        scheduler = StepLR(optimizer, step_size=45, gamma=0.5)\n",
    "    #     scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
    "    #     optimizer, mode='min', factor=0.1, patience=5\n",
    "    #       )\n",
    "    #        return {\n",
    "    #           \"optimizer\": optimizer,\n",
    "    #           \"lr_scheduler\": {\n",
    "    #               \"scheduler\": scheduler,\n",
    "    #               \"monitor\": \"val_loss\"  # 검증 손실 기반\n",
    "    #           }\n",
    "    #       }\n",
    "        return {\n",
    "        \"optimizer\": optimizer,\n",
    "        \"lr_scheduler\": {\n",
    "            \"scheduler\": scheduler,\n",
    "            \"interval\": \"epoch\",  # epoch마다 step\n",
    "            \"frequency\": 1\n",
    "        }\n",
    "    }\n",
    "\n",
    "lightning_model = LightningModel(CFS['MODEL'], num_classes, CFS[\"LR\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60799932",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5569ecf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type              | Params | Mode \n",
      "----------------------------------------------------\n",
      "0 | model | VisionTransformer | 630 M  | train\n",
      "----------------------------------------------------\n",
      "630 M     Trainable params\n",
      "0         Non-trainable params\n",
      "630 M     Total params\n",
      "2,523.146 Total estimated model params size (MB)\n",
      "684       Modules in train mode\n",
      "0         Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87ab9443fa9241f1bcc8f878c213a87c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 트레이너 설정\n",
    "trainer = Trainer(\n",
    "    max_epochs=CFS[\"EPOCHS\"],\n",
    "    accelerator='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=\"auto\",\n",
    "    logger=wandb_logger,\n",
    "    # callbacks=[\n",
    "    #     pl.callbacks.ModelCheckpoint(\n",
    "    #         dirpath=\"checkpoints/\",\n",
    "    #         filename=\"{epoch}-{val_loss:.2f}\",\n",
    "    #         save_top_k=3,\n",
    "    #         monitor=\"val_loss\"  # 검증 데이터 있을 때만 유효\n",
    "    #     )\n",
    "    # ]\n",
    ")\n",
    "\n",
    "# 학습 실행\n",
    "trainer.fit(\n",
    "    model=lightning_model,\n",
    "    datamodule=datamodule\n",
    ")\n",
    "\n",
    "wandb.finish()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9f16ad1",
   "metadata": {},
   "source": [
    "# Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2cd1f913",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3188f0f8b94c6e888dcb7f12b02328",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(\n",
    "    model=lightning_model, \n",
    "    datamodule=datamodule\n",
    ")\n",
    "\n",
    "# 4. 결과 처리\n",
    "all_preds = torch.cat(predictions).cpu().numpy()  # [n_samples]\n",
    "# 샘플 제출 파일 로드\n",
    "submission = pd.read_csv(os.path.join(data_path, \"sample_submission.csv\"))\n",
    "# 예측값으로 타겟 열 업데이트\n",
    "submission[\"target\"] = all_preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dce5d22f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 결과 저장\n",
    "submission.to_csv(\"submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574b3135",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "print(torch.cuda.memory_summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a498070f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0252388",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55108380",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f73e5887",
   "metadata": {},
   "source": [
    "# 모델저장, 불러오기 - 작업중"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "610d175c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pytorch_lightning.callbacks import ModelCheckpoint\n",
    "\n",
    "# 체크포인트 콜백 설정\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=\"checkpoints/\",               # 저장 경로\n",
    "    filename=\"{epoch}-{val_loss:.2f}\",    # 파일명 형식\n",
    "    save_top_k=2,                         # 상위 2개 모델 저장\n",
    "    monitor=\"train_loss\",                   # 모니터링 지표\n",
    "    mode=\"min\",                           # 최소화 대상\n",
    "    save_weights_only=False               # 전체 상태 저장 (권장)\n",
    ")\n",
    "\n",
    "# 트레이너에 콜백 추가\n",
    "trainer = Trainer(\n",
    "    callbacks=[checkpoint_callback],\n",
    "    max_epochs=CFS['EPOCHS'],\n",
    "    logger=wandb_logger\n",
    ")\n",
    "\n",
    "# 특정 지점에서 수동 저장\n",
    "trainer.save_checkpoint(\"manual_save.ckpt\")\n",
    "\n",
    "# 모델 아키텍처 초기화\n",
    "loaded_model = LightningModel.load_from_checkpoint(\n",
    "    checkpoint_path=\"checkpoints/epoch=10-val_loss=0.32.ckpt\",\n",
    "    model_name=CFS['MODEL'],\n",
    "    num_classes=num_classes,\n",
    "    lr=CFS['LR']\n",
    ")\n",
    "\n",
    "# 예측 실행\n",
    "predictions = trainer.predict(model=loaded_model, datamodule=datamodule)\n",
    "\n",
    "# 이전 체크포인트에서 학습 재개\n",
    "trainer = Trainer(resume_from_checkpoint=\"checkpoints/last.ckpt\")\n",
    "trainer.fit(loaded_model, datamodule=datamodule)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2bb7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 모델 아키텍처 초기화\n",
    "loaded_model = LightningModel.load_from_checkpoint(\n",
    "    checkpoint_path=\"/data/ephemeral/home/dev/doc_classification/src/pl-migration/qv19z0sy/checkpoints/epoch=79-step=4000.ckpt\",\n",
    "    model_name=CFS['MODEL'],\n",
    "    num_classes=num_classes,\n",
    "    lr=CFS['LR']\n",
    ")\n",
    "predictions = trainer.predict(model=loaded_model, datamodule=datamodule)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "cdc48cb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using default `ModelCheckpoint`. Consider installing `litmodels` package to enable `LitModelCheckpoint` for automatic upload to the Lightning model registry.\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "# 트레이너 설정\n",
    "trainer = Trainer(\n",
    "    max_epochs=CFS[\"EPOCHS\"],\n",
    "    accelerator='cuda' if torch.cuda.is_available() else 'cpu',\n",
    "    devices=\"auto\",\n",
    "    logger=wandb_logger,\n",
    "    # callbacks=[\n",
    "    #     pl.callbacks.ModelCheckpoint(\n",
    "    #         dirpath=\"checkpoints/\",\n",
    "    #         filename=\"{epoch}-{val_loss:.2f}\",\n",
    "    #         save_top_k=3,\n",
    "    #         monitor=\"val_loss\"  # 검증 데이터 있을 때만 유효\n",
    "    #     )\n",
    "    # ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ed1efb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de45b720dea46f094569e245c5cda42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Predicting: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "predictions = trainer.predict(model=loaded_model, datamodule=datamodule)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
