{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6498965f",
   "metadata": {},
   "source": [
    "#  labs.py와 augs.py 불러오기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2abff719-4661-45ce-8313-144423701d40",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import augs\n",
    "import labs\n",
    "\n",
    "importlib.reload(labs)\n",
    "importlib.reload(augs)\n",
    "\n",
    "from labs import *\n",
    "from augs import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48dbb40d-3091-4032-bdb4-0b9e2e4a16e1",
   "metadata": {},
   "source": [
    "# INIT. Processor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ab262aa5-4743-4ac4-bcf8-8f3021fb1975",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f1fd9eb7-9002-48a8-8930-b7d335a8dbc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "processor = LayoutLMv3Processor.from_pretrained(\"microsoft/layoutlmv3-base\", apply_ocr=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae305cca-c5b4-4ddd-8229-44776efef5aa",
   "metadata": {},
   "source": [
    "# DEF. Dataset and DataModule \n",
    "### 주의\n",
    "- 또한, bbox의 좌표가 layoutlm v3 (0,1000) 스케일이 아닌 픽셀 스케일을 원함\n",
    "  - 이에 따라, norm_box 변환 시점을 augment 뒤로 미뤄야 함\n",
    "\n",
    "```\n",
    "return_tensors (str, optional, defaults to \"pt\") — The type of Tensor to return. Allowable values are “np”, “pt” and “tf”.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9da6e065-e32f-494b-a127-27e367606f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_example(image_path, processor, transform=None):\n",
    "    # load image\n",
    "    if not transform:\n",
    "        image = Image.open(image_path).convert(\"RGB\")\n",
    "        image = ImageOps.exif_transpose(image)  # correct orientation\n",
    "    else:\n",
    "        image = cv2.imread(image_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # load metas\n",
    "    json_path = Path(image_path).with_suffix(\".json\")\n",
    "    meta = load_json(json_path)\n",
    "\n",
    "    # words and boxes\n",
    "    words, boxes = get_words_and_boxes(image, meta, use_norm=transform is None)\n",
    "\n",
    "    if transform is not None:\n",
    "        try:\n",
    "            augmented = transform(image=image, bboxes=boxes, words=words)\n",
    "            image = augmented['image']\n",
    "            words = augmented['words']\n",
    "            boxes = augmented['bboxes']\n",
    "            h, w = image.shape[:2]\n",
    "            boxes = [to_norm_box_with_size(b, h, w) for b in boxes]\n",
    "        except Exception as e:\n",
    "            print(\">>>>>>>>>>>>>>>>>>>>>..\", image_path)\n",
    "\n",
    "    encoding = processor(\n",
    "        images=image,\n",
    "        text=words,\n",
    "        boxes=boxes,\n",
    "        max_length=512,\n",
    "        padding=\"max_length\",\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\"\n",
    "    )\n",
    "    \n",
    "    return encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bca021a8-d798-4263-b819-d16446630e26",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D4Dataset(Dataset):\n",
    "    def __init__(self, image_paths, targets, processor, transform=None):\n",
    "        self.targets = targets\n",
    "        self.processor = processor\n",
    "        self.transform = transform\n",
    "        self.image_paths = image_paths\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.image_paths[idx]\n",
    "        encoding = prepare_example(image_path, self.processor, self.transform)\n",
    "        target = int(self.targets[os.path.basename(image_path)])\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": encoding[\"input_ids\"].squeeze(0),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].squeeze(0),\n",
    "            \"bbox\": encoding[\"bbox\"].squeeze(0),\n",
    "            \"pixel_values\": encoding[\"pixel_values\"].squeeze(0),\n",
    "            \"labels\": torch.tensor(target, dtype=torch.long)\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "44e83f36-eae8-4744-b69a-1b8e35542933",
   "metadata": {},
   "outputs": [],
   "source": [
    "class D4DataModule(LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_paths,\n",
    "        valid_paths,\n",
    "        trial_paths,\n",
    "        target_dict,\n",
    "        processor,\n",
    "        batch_size=32,\n",
    "        num_workers=4,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.train_paths = train_paths\n",
    "        self.valid_paths = valid_paths\n",
    "        self.trial_paths = trial_paths\n",
    "        self.targets = target_dict\n",
    "        self.processor = processor\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "        self.transforms = Transforms(target_size=384)\n",
    "\n",
    "    def setup(self, stage=None):\n",
    "        if stage == \"fit\":\n",
    "            self.train_ds = D4Dataset(self.train_paths, \n",
    "                                      self.targets, \n",
    "                                      self.processor,\n",
    "                                      self.transforms.make(50))\n",
    "            self.valid_ds = D4Dataset(self.valid_paths, \n",
    "                                      self.targets, \n",
    "                                      self.processor,\n",
    "                                      self.transforms.make(50))\n",
    "        if stage == \"test\" or stage is None:\n",
    "            self.trial_ds = D4Dataset(self.trial_paths, self.targets, self.processor)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.train_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=True,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator\n",
    "        )\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.valid_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator \n",
    "        )\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return DataLoader(\n",
    "            self.trial_ds,\n",
    "            batch_size=self.batch_size,\n",
    "            shuffle=False,\n",
    "            num_workers=self.num_workers,\n",
    "            collate_fn=default_data_collator \n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfd45ba1-cf97-4b28-af13-5d6d51bf5935",
   "metadata": {},
   "source": [
    "# INIT. DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "244706ef-68df-49c4-8a03-5ce376dbce28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c2ae999e03764bc6b802a0f5a08f38a1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "image_paths = grep_files(\"/root/upstg_CV/data/train\", exts=['jpg'])\n",
    "target_dict = load_csv_targets(\"/root/upstg_CV/data/train.csv\")\n",
    "label_path = \"/root/upstg_CV/data/doc_classes.json\"\n",
    "label2id, id2label = make_doc_class_mapper(label_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5833dd72-ceb6-469f-922b-cc670e47bc12",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_images, valid_images, trial_images = split_ds(image_paths,  train_ratio=0.6,  valid_ratio=0.4, test_ratio=0)\n",
    "\n",
    "data_module = D4DataModule(\n",
    "    train_paths=train_images,\n",
    "    valid_paths=valid_images,\n",
    "    trial_paths=trial_images,\n",
    "    target_dict=target_dict,\n",
    "    processor=processor,\n",
    "    batch_size=16,\n",
    "    num_workers=8\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ae712d2-7102-4593-99a7-42e9fbe8ce8e",
   "metadata": {},
   "source": [
    "# DEF) Model\n",
    "- ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight'] 크기 조절"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20dd9da8-13ec-43c3-9d91-2723454bcd1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3ForSequenceClassification as LyLmv3, LayoutLMv3Processor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59cf9574-b7cc-4ba7-85f3-beac25fae36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lym(pl.LightningModule):\n",
    "    def __init__(self, label2id, id2label):\n",
    "        super().__init__()\n",
    "        num_classes = len(label2id)\n",
    "        self.model = LyLmv3.from_pretrained(\"microsoft/layoutlmv3-base\", num_labels=num_classes)\n",
    "        self.model.config.label2id = label2id\n",
    "        self.model.config.id2label = id2label\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": Accuracy(task=\"multiclass\", num_classes=num_classes),\n",
    "            \"per-class-accuracy\" : MulticlassAccuracy(num_classes=num_classes, average=None), \n",
    "            \"roc_auc\": AUROC(task=\"multiclass\", num_classes=num_classes),\n",
    "            \"precision\": Precision(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "            \"recall\": Recall(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "            \"F1\": F1Score(task=\"multiclass\", num_classes=num_classes, average=\"macro\"),\n",
    "        }\n",
    "\n",
    "        self.train_metrics = MetricCollection(metrics, prefix=\"train_\")\n",
    "        self.valid_metrics = MetricCollection(metrics, prefix=\"valid_\")\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, bbox, pixel_values, labels=None):\n",
    "        return self.model(\n",
    "            input_ids=input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            bbox=bbox,\n",
    "            pixel_values=pixel_values,\n",
    "            labels=labels\n",
    "        )\n",
    "\n",
    "    def feed(self, batch):\n",
    "        return self(\n",
    "            batch[\"input_ids\"],\n",
    "            batch[\"attention_mask\"],\n",
    "            batch[\"bbox\"],\n",
    "            batch[\"pixel_values\"],\n",
    "            batch[\"labels\"]\n",
    "        )\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self.feed(batch)\n",
    "    \n",
    "        self.train_metrics.update(outputs.logits, labels)\n",
    "        \n",
    "        self.log(\"train_loss\", outputs.loss)\n",
    "        for name, metric in self.train_metrics.items():\n",
    "            if name == 'train_per-class-accuracy':\n",
    "                continue\n",
    "            self.log(name, metric.compute(), prog_bar=True)\n",
    "        \n",
    "        return outputs.loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        labels = batch[\"labels\"]\n",
    "        outputs = self.feed(batch)\n",
    "\n",
    "        self.valid_metrics.update(outputs.logits, labels)\n",
    "        #for 루프를 돔, 출력을 할 때 if문이 필요함 vaild-per class acuuracy면 출력을 안하도록 \n",
    "        self.log(\"valid_loss\", outputs.loss)\n",
    "        for name, metric in self.valid_metrics.items():\n",
    "            if name == 'valid_per-class-accuracy':\n",
    "                continue\n",
    "            self.log(name, metric.compute(), prog_bar=True)\n",
    "        return outputs.loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.AdamW(self.model.parameters(), lr=1e-5)\n",
    "        \n",
    "    def on_train_epoch_start(self):\n",
    "        self.train_metrics.reset()\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        metrics = self.train_metrics.compute()\n",
    "        for name, value in metrics.items():\n",
    "            if name == 'train_per-class-accuracy':  # 일단 단일 지표들만 모두 출력\n",
    "                continue\n",
    "            self.log(name, value)\n",
    "        # 아래 모델 id2label말고 한글 레이블로 하면 wandb에서 보기는 더 편함\n",
    "        per_class_acc = metrics['train_per-class-accuracy'] # 클래스별 지표\n",
    "        for i, acc in enumerate(per_class_acc):  # 각 지표별로 class_id -> 레이블로 변환하여 로그\n",
    "            label_name = self.model.config.id2label[i]  \n",
    "            self.log(f'train_acc_class_{label_name}', acc)\n",
    "\n",
    "    def on_validation_epoch_start(self):\n",
    "        self.valid_metrics.reset()\n",
    "    \n",
    "    def on_validation_epoch_end(self):\n",
    "        try:\n",
    "            metrics = self.valid_metrics.compute()\n",
    "            for name, value in metrics.items():\n",
    "                if name == 'valid_per-class-accuracy':  # 일단 단일 지표들만 모두 출력\n",
    "                    continue\n",
    "                self.log(name, value)\n",
    "        except Exception as e:\n",
    "            print(f\"Metric compute error: {e}\")\n",
    "            \n",
    "        # 아래 모델 id2label말고 한글 레이블로 하면 wandb에서 보기는 더 편함\n",
    "        per_class_acc = metrics['valid_per-class-accuracy'] # 클래스별 지표\n",
    "        for i, acc in enumerate(per_class_acc):  # 각 지표별로 class_id -> 레이블로 변환하여 로그\n",
    "            label_name = self.model.config.id2label[i]  \n",
    "            self.log(f'valid_acc_class_{label_name}', acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d5ae25e-2f63-465f-a174-8d9885d9445f",
   "metadata": {},
   "source": [
    "# Init Dashboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "37935de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c25b4435-5830-4cb9-92f5-9cea9a00f910",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdhtmdxo12345\u001b[0m (\u001b[33mdhtmdxo12345-kyonggi-university\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/root/upstg_CV/chy/llv3-aug/wandb/run-20250709_041038-x9lgsdmq</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy/runs/x9lgsdmq' target=\"_blank\">exp-llv3-aug-ost-test4</a></strong> to <a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy' target=\"_blank\">https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy/runs/x9lgsdmq' target=\"_blank\">https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy/runs/x9lgsdmq</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "exp_name = 'exp-llv3-aug-ost-test4'\n",
    "wandb.init(project='docsy', name=exp_name)\n",
    "wandb_logger = WandbLogger()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dbd8e2e-e0c4-467a-aeaf-d4421531f665",
   "metadata": {},
   "source": [
    "# RUN. Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b92995c1-7962-4108-b6e8-1b44b6cacf79",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using 16bit Automatic Mixed Precision (AMP)\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of LayoutLMv3ForSequenceClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 3090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "/data/ephemeral/home/.pyenv/versions/py12/lib/python3.12/site-packages/pytorch_lightning/loggers/wandb.py:397: There is a wandb run already in progress and newly created instances of `WandbLogger` will reuse this run. If this is not desired, call `wandb.finish()` before instantiating `WandbLogger`.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name          | Type                                | Params | Mode \n",
      "------------------------------------------------------------------------------\n",
      "0 | model         | LayoutLMv3ForSequenceClassification | 125 M  | eval \n",
      "1 | train_metrics | MetricCollection                    | 0      | train\n",
      "2 | valid_metrics | MetricCollection                    | 0      | train\n",
      "------------------------------------------------------------------------------\n",
      "125 M     Trainable params\n",
      "0         Non-trainable params\n",
      "125 M     Total params\n",
      "503.723   Total estimated model params size (MB)\n",
      "8         Modules in train mode\n",
      "243       Modules in eval mode\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd06eda161084787b23c54426c7fe84d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Sanity Checking: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/.pyenv/versions/py12/lib/python3.12/site-packages/transformers/modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n",
      "/data/ephemeral/home/.pyenv/versions/py12/lib/python3.12/site-packages/torchmetrics/utilities/prints.py:43: UserWarning: No positive samples in targets, true positive value should be meaningless. Returning zero tensor in true positive score\n",
      "  warnings.warn(*args, **kwargs)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c109fbb94c654f628dc619a9fbccea94",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Training: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "932950df629a4c1bb159a93216472235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ecec3d09a4d94a2a8e71ca2d943cef57",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0cfdd72b0a394b3cb1b6dcd9e8d3381b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "91547a7853b34c4a820bf053e3da7f71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6033477debe0425e8beadbda3e89b376",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f70b528ffa014e218090c20124d22a0a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eac9afc95a1b4ed59fe76ee0b59ca243",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "301ada164f2446bb9faae14d56bc7aed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5f66ed58b534632b581e699b3062004",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29f580bef934cda85ba7ae5a671b128",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "84734e841f894c888339188743aba8da",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "61963cc4fb8a4edda18fda3438f7cdd5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad60c5fdab7441efb366c7659dc226b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8f41caf7ed341adb20ccf44b06e5e32",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d21d4856b1e4693a5c57575978f9de9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f921a17f86440238945850b996390bf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7aef59e51c2c46e287a9d810c121c81f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e59f9c68ae8141e6a16fd7af431dfd86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9b246fed6b9241cc9bcc4edb470399c2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a784a980b0bb46c3b6a11fd74afda215",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6be1d43d06a44fb1a6bd7383ea30e7a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a101a9becf2b429e87ff0e184944951a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e82df0e53a94b2cb986b5e49dc27329",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ce2dc6cb31e40938d78085432a3b94f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c70d7ef4a7443c49f5887c3f298db63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ad48b99c829b44cbbe51fd7965a19f49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d4abb5f459a94b448162023a50d18be0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "06c62cceff4947af8e14bb60e6209d22",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2d97cdbb9e0344168540f50c24bc5b76",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "829896df6d5041c982624db3b57884fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b26f299d937e444591fb41a3a0850a6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cf6c3c1958d040a787eb82f6c0ab7dbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d0523f0311974fee89e478ea5df5c9b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab3e8b1b3976415ebd55f1363ffaaf79",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Validation: |          | 0/? [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "early_stopping = EarlyStopping(monitor='valid_loss', patience=5, mode='min')\n",
    "model_checkpoint = ModelCheckpoint(monitor=\"valid_loss\", mode=\"min\", save_top_k=3)\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    accelerator=\"gpu\",\n",
    "    precision=\"16-mixed\",\n",
    "    max_epochs=100,\n",
    "    logger=wandb_logger,\n",
    "    callbacks=[model_checkpoint, early_stopping]\n",
    ")\n",
    "\n",
    "model = Lym(label2id, id2label)\n",
    "trainer.fit(model, datamodule=data_module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a4af895",
   "metadata": {},
   "source": [
    "### 체크포인트 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "17c839eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_checkpoint(f\"./{exp_name}-last_epoch.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16140809-01b5-4e27-962d-1bda72304101",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▁▁▁▁▂▂▂▂▂▃▃▃▃▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇██████</td></tr><tr><td>train_F1</td><td>▁▄▅▆▆▆▆▆▆▇▆▆▇▇▆▇▇▇▇▇▇▇▇▇██▇█▇█▇█▇████▇█▇</td></tr><tr><td>train_acc_class_account_number</td><td>▁▇▄█▇█▇██▇▇▇██████████████████████</td></tr><tr><td>train_acc_class_application_for_payment_of_pregnancy_medical_expenses</td><td>▁▁▁▂▅▂▇██▇█████████████▇██████▇███</td></tr><tr><td>train_acc_class_car_dashboard</td><td>▁▅▅█▇█████████████████▇█▇█████████</td></tr><tr><td>train_acc_class_confirmation_of_admission_and_discharge</td><td>██▂▁▄▅▇█▂▇▅▆▄▁▇▅▆▄▂▅▄▆▆▂▄▇▆▆▄▇▇▅▇▅</td></tr><tr><td>train_acc_class_diagnosis</td><td>▁▂▅▅▄▇▇▄▇▇█▇▇▇▆▆█▆▇▇▇▆▅▇▅▆▆▆█▆▇▆▇▇</td></tr><tr><td>train_acc_class_driver_lisence</td><td>▁▄▅██▇████████████████████████████</td></tr><tr><td>train_acc_class_medical_bill_receipts</td><td>▁▅▇▆████▇█████████████████████████</td></tr><tr><td>train_acc_class_medical_outpatient_certificate</td><td>▁▁▇▇▅▂▂▂▆▂▄▁▆▇▂▆▅▇▅▅▅▆▇█▆▅▆▆▆▆▃▆▅▆</td></tr><tr><td>train_acc_class_national_id_card</td><td>▁▅██▇████▇█▇▇███▇████████▇████████</td></tr><tr><td>train_acc_class_passport</td><td>▁▆▇███████████████████████████████</td></tr><tr><td>train_acc_class_payment_confirmation</td><td>▁████▇▇▅█▇██████████▆█▇███▇▇██▇███</td></tr><tr><td>train_acc_class_pharmaceutical_receipt</td><td>▁▅▆▇▇▇▇▇█▇█▇▇█▆██▇▇█▄██▇████▇██▇▇█</td></tr><tr><td>train_acc_class_prescription</td><td>▆▁▅█▆██▇█▆███████▇██▇▇████████████</td></tr><tr><td>train_acc_class_resume</td><td>▁▁▄▅▅▆▅▇▇▆▆▇▅██▇▆▇█▇▇▇▇▇▇█▇▇▆▇▆▇▇█</td></tr><tr><td>train_acc_class_statement_of_opinion</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▃▃▄▅▃▅▆▅▄▄▅▇▅▅▆▇▅▆▇▆█▅</td></tr><tr><td>train_acc_class_vehicle_registration_certificate</td><td>▁▃▅▆██▇█▆█▇▇▇█▇██▇███████████▇▇█▇▇</td></tr><tr><td>train_acc_class_vehicle_registration_plate</td><td>▁████▁███████████████████████▁████</td></tr><tr><td>train_accuracy</td><td>▁▃▄▅▅▆▆▆▆▆▆▆▇▇▇▇▇▇▇▇▇▆▇█▇▇▇▇██▇█▇█▇▇█▇█▇</td></tr><tr><td>train_loss</td><td>█▆▄▄▃▂▃▂▃▃▂▁▂▂▂▂▂▂▂▁▂▁▂▁▁▁▁▂▂▂▁▁▁▁▁▁▁▁▁▃</td></tr><tr><td>train_precision</td><td>▁▂▃▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇█▇█▇█▇██▇█▇█▇▇▇█▇▇</td></tr><tr><td>train_recall</td><td>▁▃▃▄▅▆▆▆▆▆▆▇▇▆▆▆▇▇▇▇▇▇▇▇▇▇██▇▇█▇▇▇▇▇█▇█▇</td></tr><tr><td>train_roc_auc</td><td>▁▆▇▇█▅████████▁█████████████████████████</td></tr><tr><td>trainer/global_step</td><td>▁▁▁▁▁▂▂▂▂▃▃▃▃▃▄▄▄▄▄▄▅▅▅▅▅▅▅▅▆▆▆▆▇▇▇█████</td></tr><tr><td>valid_F1</td><td>▁▃▅▆▆▆▇▆▇▇▇▇▇█▇█████▇█████████████</td></tr><tr><td>valid_acc_class_account_number</td><td>▁▇▄█▇█▇██▇▇▇██████████████████████</td></tr><tr><td>valid_acc_class_application_for_payment_of_pregnancy_medical_expenses</td><td>▁▁▁▂▅▂▇██▇█████████████▇██████▇███</td></tr><tr><td>valid_acc_class_car_dashboard</td><td>▁▅▅█▇█████████████████▇█▇█████████</td></tr><tr><td>valid_acc_class_confirmation_of_admission_and_discharge</td><td>██▂▁▄▅▇█▂▇▅▆▄▁▇▅▆▄▂▅▄▆▆▂▄▇▆▆▄▇▇▅▇▅</td></tr><tr><td>valid_acc_class_diagnosis</td><td>▁▂▅▅▄▇▇▄▇▇█▇▇▇▆▆█▆▇▇▇▆▅▇▅▆▆▆█▆▇▆▇▇</td></tr><tr><td>valid_acc_class_driver_lisence</td><td>▁▄▅██▇████████████████████████████</td></tr><tr><td>valid_acc_class_medical_bill_receipts</td><td>▁▅▇▆████▇█████████████████████████</td></tr><tr><td>valid_acc_class_medical_outpatient_certificate</td><td>▁▁▇▇▅▂▂▂▆▂▄▁▆▇▂▆▅▇▅▅▅▆▇█▆▅▆▆▆▆▃▆▅▆</td></tr><tr><td>valid_acc_class_national_id_card</td><td>▁▅██▇████▇█▇▇███▇████████▇████████</td></tr><tr><td>valid_acc_class_passport</td><td>▁▆▇███████████████████████████████</td></tr><tr><td>valid_acc_class_payment_confirmation</td><td>▁████▇▇▅█▇██████████▆█▇███▇▇██▇███</td></tr><tr><td>valid_acc_class_pharmaceutical_receipt</td><td>▁▅▆▇▇▇▇▇█▇█▇▇█▆██▇▇█▄██▇████▇██▇▇█</td></tr><tr><td>valid_acc_class_prescription</td><td>▆▁▅█▆██▇█▆███████▇██▇▇████████████</td></tr><tr><td>valid_acc_class_resume</td><td>▁▁▄▅▅▆▅▇▇▆▆▇▅██▇▆▇█▇▇▇▇▇▇█▇▇▆▇▆▇▇█</td></tr><tr><td>valid_acc_class_statement_of_opinion</td><td>▁▁▁▁▁▁▁▁▁▁▂▁▃▃▄▅▃▅▆▅▄▄▅▇▅▅▆▇▅▆▇▆█▅</td></tr><tr><td>valid_acc_class_vehicle_registration_certificate</td><td>▁▃▅▆██▇█▆█▇▇▇█▇██▇███████████▇▇█▇▇</td></tr><tr><td>valid_acc_class_vehicle_registration_plate</td><td>▁████▁███████████████████████▁████</td></tr><tr><td>valid_accuracy</td><td>▁▄▆▆▇▇▇▇▇▇█▇██▇█████▇█████████████</td></tr><tr><td>valid_loss</td><td>█▆▄▃▃▂▂▂▂▂▁▂▁▁▁▁▁▁▁▁▂▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>valid_precision</td><td>▁▃▆▆▆▆▇▇▇▇█▇▇█▇███▇█▇█████████████</td></tr><tr><td>valid_recall</td><td>▁▃▅▆▆▆▇▆▇▇▇▇▇█▇█████▇█████████████</td></tr><tr><td>valid_roc_auc</td><td>▁▅▆▇▇▇█▇██████████████████████████</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>33</td></tr><tr><td>train_F1</td><td>0.90351</td></tr><tr><td>train_acc_class_account_number</td><td>1</td></tr><tr><td>train_acc_class_application_for_payment_of_pregnancy_medical_expenses</td><td>1</td></tr><tr><td>train_acc_class_car_dashboard</td><td>0.97143</td></tr><tr><td>train_acc_class_confirmation_of_admission_and_discharge</td><td>0.55556</td></tr><tr><td>train_acc_class_diagnosis</td><td>0.80488</td></tr><tr><td>train_acc_class_driver_lisence</td><td>1</td></tr><tr><td>train_acc_class_medical_bill_receipts</td><td>0.97872</td></tr><tr><td>train_acc_class_medical_outpatient_certificate</td><td>0.7381</td></tr><tr><td>train_acc_class_national_id_card</td><td>1</td></tr><tr><td>train_acc_class_passport</td><td>1</td></tr><tr><td>train_acc_class_payment_confirmation</td><td>0.96078</td></tr><tr><td>train_acc_class_pharmaceutical_receipt</td><td>0.95</td></tr><tr><td>train_acc_class_prescription</td><td>0.97297</td></tr><tr><td>train_acc_class_resume</td><td>0.94118</td></tr><tr><td>train_acc_class_statement_of_opinion</td><td>0.52632</td></tr><tr><td>train_acc_class_vehicle_registration_certificate</td><td>0.925</td></tr><tr><td>train_acc_class_vehicle_registration_plate</td><td>1</td></tr><tr><td>train_accuracy</td><td>0.91069</td></tr><tr><td>train_loss</td><td>0.81888</td></tr><tr><td>train_precision</td><td>0.90948</td></tr><tr><td>train_recall</td><td>0.90147</td></tr><tr><td>train_roc_auc</td><td>0.99379</td></tr><tr><td>trainer/global_step</td><td>2005</td></tr><tr><td>valid_F1</td><td>0.90351</td></tr><tr><td>valid_acc_class_account_number</td><td>1</td></tr><tr><td>valid_acc_class_application_for_payment_of_pregnancy_medical_expenses</td><td>1</td></tr><tr><td>valid_acc_class_car_dashboard</td><td>0.97143</td></tr><tr><td>valid_acc_class_confirmation_of_admission_and_discharge</td><td>0.55556</td></tr><tr><td>valid_acc_class_diagnosis</td><td>0.80488</td></tr><tr><td>valid_acc_class_driver_lisence</td><td>1</td></tr><tr><td>valid_acc_class_medical_bill_receipts</td><td>0.97872</td></tr><tr><td>valid_acc_class_medical_outpatient_certificate</td><td>0.7381</td></tr><tr><td>valid_acc_class_national_id_card</td><td>1</td></tr><tr><td>valid_acc_class_passport</td><td>1</td></tr><tr><td>valid_acc_class_payment_confirmation</td><td>0.96078</td></tr><tr><td>valid_acc_class_pharmaceutical_receipt</td><td>0.95</td></tr><tr><td>valid_acc_class_prescription</td><td>0.97297</td></tr><tr><td>valid_acc_class_resume</td><td>0.94118</td></tr><tr><td>valid_acc_class_statement_of_opinion</td><td>0.52632</td></tr><tr><td>valid_acc_class_vehicle_registration_certificate</td><td>0.925</td></tr><tr><td>valid_acc_class_vehicle_registration_plate</td><td>1</td></tr><tr><td>valid_accuracy</td><td>0.91069</td></tr><tr><td>valid_loss</td><td>0.30274</td></tr><tr><td>valid_precision</td><td>0.90948</td></tr><tr><td>valid_recall</td><td>0.90147</td></tr><tr><td>valid_roc_auc</td><td>0.99379</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">exp-llv3-aug-ost-test4</strong> at: <a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy/runs/x9lgsdmq' target=\"_blank\">https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy/runs/x9lgsdmq</a><br> View project at: <a href='https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy' target=\"_blank\">https://wandb.ai/dhtmdxo12345-kyonggi-university/docsy</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250709_041038-x9lgsdmq/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d5c3331",
   "metadata": {},
   "source": [
    "## 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02dd6954",
   "metadata": {},
   "source": [
    "### bbox정규화 및 json파일에서 추출하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "32e3d8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_bbox(bbox, width, height):\n",
    "    \"\"\"\n",
    "    LayoutLMv3에서 요구하는 0~1000 정규화된 bbox\n",
    "    \"\"\"\n",
    "    x1, y1, x2, y2 = bbox\n",
    "    return [\n",
    "        int(x1 / width * 1000),\n",
    "        int(y1 / height * 1000),\n",
    "        int(x2 / width * 1000),\n",
    "        int(y2 / height * 1000)\n",
    "    ]\n",
    "\n",
    "    \n",
    "def to_norm_box_with_size(box, h, w):\n",
    "    x0, y0, x1, y1 = box\n",
    "\n",
    "    x0_norm = int((x0 / w) * 1000)\n",
    "    y0_norm = int((y0 / h) * 1000)\n",
    "    x1_norm = int((x1 / w) * 1000)\n",
    "    y1_norm = int((y1 / h) * 1000)\n",
    "\n",
    "    x0_norm = max(0, min(1000, x0_norm))\n",
    "    y0_norm = max(0, min(1000, y0_norm))\n",
    "    x1_norm = max(0, min(1000, x1_norm))\n",
    "    y1_norm = max(0, min(1000, y1_norm))\n",
    "\n",
    "    return [x0_norm, y0_norm, x1_norm, y1_norm]\n",
    "\n",
    "def load_ocr_from_json(image_path):\n",
    "    \"\"\"\n",
    "    test 이미지 경로를 입력받아 동일한 이름의 JSON에서 OCR 정보를 추출하고,\n",
    "    LayoutLMv3에 맞게 정규화된 text와 bbox 리스트를 반환\n",
    "    \"\"\"\n",
    "    json_path = image_path.replace(\".jpg\", \".json\")\n",
    "\n",
    "    # 이미지 크기 확인\n",
    "    img = Image.open(image_path).convert(\"RGB\")\n",
    "    width, height = img.size\n",
    "\n",
    "    # JSON 읽기\n",
    "    with open(json_path, \"r\", encoding=\"utf-8\") as f:\n",
    "        data = json.load(f)\n",
    "\n",
    "    words = []\n",
    "    boxes = []\n",
    "\n",
    "    for ann in data[\"annotation\"]:\n",
    "        word = ann[\"text\"]\n",
    "        bbox = ann[\"box\"]  # [x1, y1, x2, y2]\n",
    "        score = ann.get(\"score\", 1.0)\n",
    "\n",
    "        # 조건 필터링 (예: score가 너무 낮은 항목 제외)\n",
    "        if word.strip() and score > 0.5:\n",
    "            words.append(word)\n",
    "            boxes.append(to_norm_box_with_size(bbox, width, height))\n",
    "\n",
    "    return words, boxes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "856b5c10",
   "metadata": {},
   "source": [
    "### processor 구성하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3a32ced5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import LayoutLMv3ImageProcessor, AutoTokenizer, LayoutLMv3Processor\n",
    "\n",
    "# 1. ImageProcessor는 apply_ocr=False로 생성\n",
    "image_processor = LayoutLMv3ImageProcessor(apply_ocr=False)\n",
    "\n",
    "# 2. 토크나이저 로드\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/layoutlmv3-base\")\n",
    "\n",
    "# 3. 최종 processor 구성\n",
    "processor = LayoutLMv3Processor(image_processor=image_processor, tokenizer=tokenizer)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99fff437",
   "metadata": {},
   "source": [
    "### 테스트 데이터 예측"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ee1c137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ckpt_path = \"/root/upstg_CV/chy/llv3-aug/exp-llv3-aug-ost-test1-last_epoch.ckpt\"\n",
    "# model = Lym.load_from_checkpoint(ckpt_path, id2label=id2label, label2id=label2id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a2eef9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31ce5b9738d449a6b12b186f6327c715",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "304d246871d34336bd3214c82328980d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 모델 및 processor 불러오기\n",
    "model.eval().cuda()\n",
    "# 테스트 이미지 경로\n",
    "test_img_paths = grep_files(\"/root/upstg_CV/deskewed-test\", exts=['jpg'])\n",
    "\n",
    "preds = []\n",
    "\n",
    "# ✅ 추론 루프\n",
    "for path in tqdm(test_img_paths):\n",
    "    img = cv2.imread(path)\n",
    "    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "    words, boxes = load_ocr_from_json(path)\n",
    "\n",
    "    inputs = processor(\n",
    "        images=img,\n",
    "        text=words,\n",
    "        boxes=boxes,\n",
    "        return_tensors=\"pt\",\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=512\n",
    "    )\n",
    "\n",
    "\n",
    "    inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "    # 추론\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "        pred_class = torch.argmax(logits, dim=1).item()\n",
    "\n",
    "    preds.append((path, pred_class))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e334570d",
   "metadata": {},
   "source": [
    "### submission 데이터에 저장"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "86c06093",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# ✅ 예측 결과를 sample_submission.csv에 반영\n",
    "def write_csv_value(csv_path, preds):\n",
    "    df = pd.read_csv(csv_path)\n",
    "    for path, pred in preds:\n",
    "        fname = os.path.basename(path)\n",
    "        df.loc[df['ID'] == fname, 'target'] = pred\n",
    "    df.to_csv(csv_path, index=False, encoding='utf-8')\n",
    "\n",
    "write_csv_value(\"/root/upstg_CV/data/lymv3_ver3.csv\", preds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8ceb74",
   "metadata": {},
   "source": [
    "# 분류기가 예측한 데이터의 클래스별 확률분포"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9484480a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_proba_map_layoutlmv3(image_paths, model, processor, load_ocr_from_json_no_normalize, class_names=None):\n",
    "    \"\"\"\n",
    "    LayoutLMv3 모델을 사용하여 이미지 분류 확률 맵을 생성하는 함수\n",
    "    \n",
    "    Args:\n",
    "        image_paths: 이미지 경로 리스트\n",
    "        model: 학습된 LayoutLMv3 모델\n",
    "        processor: LayoutLMv3 processor\n",
    "        load_ocr_from_json: OCR 데이터를 로드하는 함수\n",
    "        class_names: 클래스 이름 리스트 (인덱스 순서대로). None이면 기본값 사용\n",
    "    \n",
    "    Returns:\n",
    "        rows: 각 이미지별 분류 확률 정보가 담긴 딕셔너리 리스트\n",
    "    \"\"\"\n",
    "    # 17개 클래스에 맞게 수정\n",
    "    ids = list(range(17))  # [0, 1, 2, ..., 16]\n",
    "    \n",
    "    # 클래스 이름이 제공되지 않으면 기본값 사용\n",
    "    if class_names is None:\n",
    "        # 주의: 이 순서가 모델 학습 시 사용한 순서와 일치해야 합니다!\n",
    "        class_names = [\n",
    "            \"계좌번호\",\n",
    "            \"임신/출산 신청서\", \n",
    "            \"자동차 계기판\",\n",
    "            \"입/퇴원 확인서\",\n",
    "            \"진단서\",\n",
    "            \"운전면허증\",\n",
    "            \"진료/의료비 영수증\",\n",
    "            \"외래/진료/통원/치료 확인서\",\n",
    "            \"주민등록증\",\n",
    "            \"여권\",\n",
    "            \"(진료비/약제비) 납입 확인서\",\n",
    "            \"약국/영수증\",\n",
    "            \"처방전\",\n",
    "            \"이력서\",\n",
    "            \"소견서\",\n",
    "            \"자동차 등록증\",\n",
    "            \"자동차 번호판\"\n",
    "        ]\n",
    "    \n",
    "    labels = class_names\n",
    "    \n",
    "    model.eval()\n",
    "    rows = []\n",
    "    \n",
    "    # ✅ 추론 루프 - 확률 분포 계산\n",
    "    for path in tqdm(image_paths):\n",
    "        img = cv2.imread(path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        words, boxes = load_ocr_from_json_no_normalize(path)\n",
    "\n",
    "        inputs = processor(\n",
    "            images=img,\n",
    "            text=words,\n",
    "            boxes=boxes,\n",
    "            return_tensors=\"pt\",\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=512\n",
    "        )\n",
    "\n",
    "        inputs = {k: v.cuda() for k, v in inputs.items()}\n",
    "\n",
    "        # 추론 - 확률 분포 계산\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "            \n",
    "            # 소프트맥스를 적용하여 확률 분포 계산\n",
    "            probs = F.softmax(logits, dim=1)\n",
    "            probs_np = probs.cpu().numpy().squeeze()  # (num_classes,)\n",
    "            \n",
    "            # 가장 높은 확률의 클래스 찾기\n",
    "            pred_class = torch.argmax(logits, dim=1).item()\n",
    "        \n",
    "        # 확률을 소수점 2자리로 반올림\n",
    "        probs_rounded = [float(f\"{p:.2f}\") for p in probs_np]\n",
    "        \n",
    "        # 예측 결과 생성\n",
    "        guess = f\"{labels[pred_class]} [{ids[pred_class]}]\"\n",
    "        \n",
    "        # 결과 딕셔너리 생성\n",
    "        item = {\n",
    "            'code': os.path.basename(path),\n",
    "            'guess': guess\n",
    "        }\n",
    "        \n",
    "        # 각 클래스별 확률 추가\n",
    "        for j in range(len(ids)):\n",
    "            label = f\"{labels[j]} [{ids[j]}]\"\n",
    "            item[label] = probs_rounded[j]\n",
    "        \n",
    "        rows.append(item)\n",
    "    \n",
    "    # 파일명 기준으로 정렬\n",
    "    rows = sorted(rows, key=lambda x: x['code'])\n",
    "    return rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3fddac07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_results_to_csv(results, filename):\n",
    "    \"\"\"\n",
    "    결과를 CSV 파일로 저장하는 함수\n",
    "    \n",
    "    Args:\n",
    "        results: make_proba_map_layoutlmv3의 결과 (딕셔너리 리스트)\n",
    "        filename: 저장할 파일명\n",
    "    \"\"\"\n",
    "    import pandas as pd\n",
    "    \n",
    "    # 딕셔너리 리스트를 DataFrame으로 변환\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # CSV로 저장\n",
    "    df.to_csv(filename, index=False, encoding='utf-8-sig')  # 한글 지원을 위해 utf-8-sig 사용\n",
    "    print(f\"결과가 {filename}에 저장되었습니다.\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6adadca7",
   "metadata": {},
   "source": [
    "### 확률 분포 및 추론 함수 실행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "de57f303",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "847f8d8adb1f4c59859c693f9b25602f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3140 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/ephemeral/home/.pyenv/versions/py12/lib/python3.12/site-packages/transformers/modeling_utils.py:1731: FutureWarning: The `device` argument is deprecated and will be removed in v5 of Transformers.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "결과가 [ost]lym3-proba-map2.csv에 저장되었습니다.\n",
      "총 3140개 이미지 처리 완료\n",
      "                   code         guess  계좌번호 [0]  임신/출산 신청서 [1]  자동차 계기판 [2]  \\\n",
      "0  0008fdb22ddce0ce.jpg  자동차 번호판 [16]      0.01            0.0         0.01   \n",
      "1  00091bffdffd83de.jpg      처방전 [12]      0.00            0.0         0.00   \n",
      "2  00396fbc1f6cc21d.jpg     운전면허증 [5]      0.00            0.0         0.00   \n",
      "3  00471f8038d9c4b6.jpg      이력서 [13]      0.01            0.0         0.00   \n",
      "4  00901f504008d884.jpg   자동차 계기판 [2]      0.00            0.0         0.99   \n",
      "\n",
      "   입/퇴원 확인서 [3]  진단서 [4]  운전면허증 [5]  진료/의료비 영수증 [6]  외래/진료/통원/치료 확인서 [7]  \\\n",
      "0          0.00     0.00       0.00            0.00                 0.00   \n",
      "1          0.00     0.00       0.00            0.01                 0.01   \n",
      "2          0.00     0.00       0.97            0.00                 0.00   \n",
      "3          0.34     0.01       0.01            0.01                 0.04   \n",
      "4          0.00     0.00       0.00            0.00                 0.00   \n",
      "\n",
      "   주민등록증 [8]  여권 [9]  (진료비/약제비) 납입 확인서 [10]  약국/영수증 [11]  처방전 [12]  이력서 [13]  \\\n",
      "0       0.03    0.01                   0.00         0.00      0.00      0.00   \n",
      "1       0.00    0.00                   0.00         0.01      0.89      0.00   \n",
      "2       0.01    0.00                   0.00         0.00      0.00      0.00   \n",
      "3       0.01    0.01                   0.01         0.02      0.01      0.46   \n",
      "4       0.00    0.00                   0.00         0.00      0.00      0.00   \n",
      "\n",
      "   소견서 [14]  자동차 등록증 [15]  자동차 번호판 [16]  \n",
      "0      0.00          0.00          0.91  \n",
      "1      0.00          0.06          0.00  \n",
      "2      0.00          0.00          0.00  \n",
      "3      0.04          0.00          0.01  \n",
      "4      0.00          0.00          0.00  \n"
     ]
    }
   ],
   "source": [
    "# 1. 추론 실행\n",
    "results = make_proba_map_layoutlmv3(\n",
    "    test_img_paths, \n",
    "    model, \n",
    "    processor, \n",
    "    load_ocr_from_json\n",
    ")\n",
    "\n",
    "# 2. CSV 저장\n",
    "df = save_results_to_csv(results, \"[ost]lym3-proba-map2.csv\")\n",
    "\n",
    "# 3. 결과 확인\n",
    "print(f\"총 {len(df)}개 이미지 처리 완료\")\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ff36a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
